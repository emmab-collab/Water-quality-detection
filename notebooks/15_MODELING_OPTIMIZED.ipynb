{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Modélisation Optimisée\n",
    "\n",
    "## Learnings des versions précédentes\n",
    "\n",
    "- **V2** (toutes features) : R² local 0.80, score soumission 0.002\n",
    "- **V3 all_temporal** : score soumission **0.05** (meilleur)\n",
    "- Autres stratégies : -0.2\n",
    "\n",
    "## Stratégie\n",
    "\n",
    "1. Features temporelles avec **très faible** corrélation géographique (< 0.15)\n",
    "2. Modèles simples : Ridge, Lasso, ElasticNet\n",
    "3. XGBoost avec forte régularisation\n",
    "4. Ensemble de modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK!\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, GroupKFold\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-md",
   "metadata": {},
   "source": [
    "## Étape 1 : Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training : (9319, 79)\n",
      "Test : (200, 79)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"../data/processed/merged_training.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/merged_validation.csv\")\n",
    "\n",
    "TARGET_COLS = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n",
    "TARGET_NAMES = ['Alkalinity', 'Conductivity', 'Phosphorus']\n",
    "\n",
    "print(f\"Training : {train_df.shape}\")\n",
    "print(f\"Test : {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-md",
   "metadata": {},
   "source": [
    "## Étape 2 : Sélectionner les features les moins géographiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "features-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toutes features : 73\n",
      "Corrélation < 0.15 : 56\n",
      "Corrélation < 0.10 : 36\n",
      "\n",
      "Features très faible corrélation (<0.10) :\n",
      "  blue: 0.003\n",
      "  green: 0.003\n",
      "  red: 0.016\n",
      "  nir: 0.082\n",
      "  swir16: 0.094\n",
      "  blue_std: 0.001\n",
      "  green_std: 0.029\n",
      "  red_std: 0.010\n",
      "  swir16_std: 0.006\n",
      "  swir22_std: 0.002\n",
      "  NDWI: 0.096\n",
      "  MNDWI: 0.100\n",
      "  NDWI_std: 0.082\n",
      "  MNDWI_std: 0.051\n",
      "  aet: 0.014\n",
      "  ppt: 0.009\n",
      "  ppt_lag1: 0.013\n",
      "  ppt_lag2: 0.017\n",
      "  ppt_lag3: 0.008\n",
      "  ppt_sum4: 0.016\n",
      "  ppt_mean4: 0.016\n",
      "  ppt_anomaly: 0.003\n",
      "  tmin: 0.005\n",
      "  soil_anomaly: 0.013\n",
      "  def_lag1: 0.096\n",
      "  def_lag2: 0.091\n",
      "  def_lag3: 0.089\n",
      "  def_anomaly: 0.016\n",
      "  pdsi: 0.011\n",
      "  vpd_anomaly: 0.028\n",
      "  lc_cropland: 0.014\n",
      "  lc_builtup: 0.039\n",
      "  lc_bare: 0.096\n",
      "  lc_wetland: 0.032\n",
      "  soil_sand: 0.017\n",
      "  aspect: 0.017\n"
     ]
    }
   ],
   "source": [
    "# Colonnes à exclure\n",
    "EXCLUDE_COLS = ['Latitude', 'Longitude', 'Sample Date'] + TARGET_COLS\n",
    "\n",
    "# Toutes les features\n",
    "all_features = [c for c in train_df.columns if c not in EXCLUDE_COLS]\n",
    "\n",
    "# Calculer la corrélation avec la latitude\n",
    "correlations = {}\n",
    "for col in all_features:\n",
    "    try:\n",
    "        corr = np.abs(train_df[col].corr(train_df['Latitude']))\n",
    "        if not np.isnan(corr):\n",
    "            correlations[col] = corr\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Features avec corrélation < 0.15 (très faible)\n",
    "low_geo_features = [f for f, c in correlations.items() if c < 0.15]\n",
    "\n",
    "# Features avec corrélation < 0.10 (extrêmement faible)\n",
    "very_low_geo_features = [f for f, c in correlations.items() if c < 0.10]\n",
    "\n",
    "print(f\"Toutes features : {len(all_features)}\")\n",
    "print(f\"Corrélation < 0.15 : {len(low_geo_features)}\")\n",
    "print(f\"Corrélation < 0.10 : {len(very_low_geo_features)}\")\n",
    "\n",
    "print(f\"\\nFeatures très faible corrélation (<0.10) :\")\n",
    "for f in very_low_geo_features:\n",
    "    print(f\"  {f}: {correlations[f]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prep-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (9319, 36)\n",
      "X_test : (200, 36)\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# PRÉPARER LES DONNÉES\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_features(df, feature_cols):\n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    # Encoder water_type si présent\n",
    "    if 'water_type' in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X['water_type'] = le.fit_transform(X['water_type'].fillna('unknown'))\n",
    "    \n",
    "    # Convertir en numérique\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "    \n",
    "    # Remplir les NaN\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Préparer avec features très faible corrélation\n",
    "X_train = prepare_features(train_df, very_low_geo_features)\n",
    "X_test = prepare_features(test_df, very_low_geo_features)\n",
    "y_train = train_df[TARGET_COLS].copy()\n",
    "\n",
    "print(f\"X_train : {X_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}\")\n",
    "\n",
    "# Créer clusters pour validation spatiale\n",
    "kmeans = KMeans(n_clusters=10, random_state=42, n_init=10)\n",
    "train_df['geo_cluster'] = kmeans.fit_predict(train_df[['Latitude', 'Longitude']])\n",
    "groups = train_df['geo_cluster'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-md",
   "metadata": {},
   "source": [
    "## Étape 3 : Tester différents modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "models-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation spatiale avec features très faible corrélation géo\n",
      "============================================================\n",
      "\n",
      "Ridge (alpha=10):\n",
      "  Alkalinity: R² = -0.5994\n",
      "  Conductivity: R² = -0.5084\n",
      "  Phosphorus: R² = -1.2971\n",
      "  → MOYENNE: -0.8016\n",
      "\n",
      "Ridge (alpha=100):\n",
      "  Alkalinity: R² = -0.5715\n",
      "  Conductivity: R² = -0.4526\n",
      "  Phosphorus: R² = -1.1020\n",
      "  → MOYENNE: -0.7087\n",
      "\n",
      "Lasso (alpha=1):\n",
      "  Alkalinity: R² = -0.5383\n",
      "  Conductivity: R² = -0.4724\n",
      "  Phosphorus: R² = -0.8243\n",
      "  → MOYENNE: -0.6116\n",
      "\n",
      "ElasticNet:\n",
      "  Alkalinity: R² = -0.5644\n",
      "  Conductivity: R² = -0.4962\n",
      "  Phosphorus: R² = -0.5264\n",
      "  → MOYENNE: -0.5290\n",
      "\n",
      "XGBoost (regularized):\n",
      "  Alkalinity: R² = -0.6717\n",
      "  Conductivity: R² = -0.3598\n",
      "  Phosphorus: R² = -0.4362\n",
      "  → MOYENNE: -0.4892\n",
      "\n",
      "LightGBM (regularized):\n",
      "  Alkalinity: R² = -0.6669\n",
      "  Conductivity: R² = -0.3256\n",
      "  Phosphorus: R² = -0.4944\n",
      "  → MOYENNE: -0.4957\n",
      "\n",
      "============================================================\n",
      "CLASSEMENT:\n",
      "  XGBoost (regularized): -0.4892\n",
      "  LightGBM (regularized): -0.4957\n",
      "  ElasticNet: -0.5290\n",
      "  Lasso (alpha=1): -0.6116\n",
      "  Ridge (alpha=100): -0.7087\n",
      "  Ridge (alpha=10): -0.8016\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TESTER DIFFÉRENTS MODÈLES\n",
    "# =============================================================================\n",
    "\n",
    "# Normaliser pour les modèles linéaires\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "models = {\n",
    "    'Ridge (alpha=10)': Ridge(alpha=10),\n",
    "    'Ridge (alpha=100)': Ridge(alpha=100),\n",
    "    'Lasso (alpha=1)': Lasso(alpha=1),\n",
    "    'ElasticNet': ElasticNet(alpha=1, l1_ratio=0.5),\n",
    "    'XGBoost (regularized)': xgb.XGBRegressor(\n",
    "        n_estimators=50, max_depth=3, learning_rate=0.05,\n",
    "        reg_alpha=5, reg_lambda=5, subsample=0.7,\n",
    "        random_state=42, n_jobs=-1, verbosity=0\n",
    "    ),\n",
    "    'LightGBM (regularized)': lgb.LGBMRegressor(\n",
    "        n_estimators=50, max_depth=3, learning_rate=0.05,\n",
    "        reg_alpha=5, reg_lambda=5, subsample=0.7,\n",
    "        random_state=42, n_jobs=-1, verbosity=-1\n",
    "    ),\n",
    "}\n",
    "\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Validation spatiale avec features très faible corrélation géo\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    scores_by_target = []\n",
    "    for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "        # Utiliser données scaled pour modèles linéaires\n",
    "        if 'Ridge' in model_name or 'Lasso' in model_name or 'Elastic' in model_name:\n",
    "            X_use = X_train_scaled\n",
    "        else:\n",
    "            X_use = X_train\n",
    "        \n",
    "        scores = cross_val_score(\n",
    "            model, X_use, y_train[target],\n",
    "            cv=gkf, groups=groups, scoring='r2'\n",
    "        )\n",
    "        scores_by_target.append(scores.mean())\n",
    "        print(f\"  {target_name}: R² = {scores.mean():.4f}\")\n",
    "    \n",
    "    mean_score = np.mean(scores_by_target)\n",
    "    results[model_name] = mean_score\n",
    "    print(f\"  → MOYENNE: {mean_score:.4f}\")\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"CLASSEMENT:\")\n",
    "for name, score in sorted(results.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {name}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ensemble-md",
   "metadata": {},
   "source": [
    "## Étape 4 : Essayer un ensemble simple (moyenne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ensemble-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Génération des prédictions avec ensemble\n",
      "============================================================\n",
      "\n",
      "Ridge:\n",
      "  Alkalinity: mean=92.7\n",
      "  Conductivity: mean=361.9\n",
      "  Phosphorus: mean=22.9\n",
      "\n",
      "XGBoost:\n",
      "  Alkalinity: mean=94.3\n",
      "  Conductivity: mean=312.0\n",
      "  Phosphorus: mean=25.0\n",
      "\n",
      "LightGBM:\n",
      "  Alkalinity: mean=94.0\n",
      "  Conductivity: mean=311.3\n",
      "  Phosphorus: mean=26.3\n",
      "\n",
      "Ensemble (moyenne):\n",
      "  Alkalinity: mean=93.7\n",
      "  Conductivity: mean=328.4\n",
      "  Phosphorus: mean=24.7\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# ENSEMBLE : MOYENNE DE PLUSIEURS MODÈLES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération des prédictions avec ensemble\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Modèles pour l'ensemble\n",
    "ensemble_models = [\n",
    "    ('Ridge', Ridge(alpha=100)),\n",
    "    ('XGBoost', xgb.XGBRegressor(\n",
    "        n_estimators=50, max_depth=3, learning_rate=0.05,\n",
    "        reg_alpha=5, reg_lambda=5, random_state=42, n_jobs=-1, verbosity=0\n",
    "    )),\n",
    "    ('LightGBM', lgb.LGBMRegressor(\n",
    "        n_estimators=50, max_depth=3, learning_rate=0.05,\n",
    "        reg_alpha=5, reg_lambda=5, random_state=42, n_jobs=-1, verbosity=-1\n",
    "    )),\n",
    "]\n",
    "\n",
    "predictions_ensemble = {target: [] for target in TARGET_COLS}\n",
    "\n",
    "for model_name, model in ensemble_models:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    \n",
    "    for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "        if 'Ridge' in model_name:\n",
    "            model.fit(X_train_scaled, y_train[target])\n",
    "            pred = model.predict(X_test_scaled)\n",
    "        else:\n",
    "            model.fit(X_train, y_train[target])\n",
    "            pred = model.predict(X_test)\n",
    "        \n",
    "        pred = np.maximum(pred, 0)  # Pas de valeurs négatives\n",
    "        predictions_ensemble[target].append(pred)\n",
    "        print(f\"  {target_name}: mean={pred.mean():.1f}\")\n",
    "\n",
    "# Moyenne des prédictions\n",
    "final_predictions = {}\n",
    "print(\"\\nEnsemble (moyenne):\")\n",
    "for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "    preds = np.array(predictions_ensemble[target])\n",
    "    final_predictions[target] = np.mean(preds, axis=0)\n",
    "    print(f\"  {target_name}: mean={final_predictions[target].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "submit-md",
   "metadata": {},
   "source": [
    "## Étape 5 : Générer les soumissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "submit-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ submission_ensemble_v4.csv\n",
      "✅ submission_ridge_v4.csv\n",
      "✅ submission_xgb_regularized_v4.csv\n",
      "\n",
      "3 fichiers créés dans ../data/\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GÉNÉRER LES SOUMISSIONS\n",
    "# =============================================================================\n",
    "\n",
    "template = pd.read_csv(\"../data/raw/submission_template.csv\")\n",
    "\n",
    "# Soumission 1: Ensemble\n",
    "sub_ensemble = template.copy()\n",
    "for target in TARGET_COLS:\n",
    "    sub_ensemble[target] = final_predictions[target]\n",
    "sub_ensemble.to_csv(\"../data/submission_ensemble_v4.csv\", index=False)\n",
    "print(\"✅ submission_ensemble_v4.csv\")\n",
    "\n",
    "# Soumission 2: Ridge seul\n",
    "sub_ridge = template.copy()\n",
    "ridge = Ridge(alpha=100)\n",
    "for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "    ridge.fit(X_train_scaled, y_train[target])\n",
    "    pred = np.maximum(ridge.predict(X_test_scaled), 0)\n",
    "    sub_ridge[target] = pred\n",
    "sub_ridge.to_csv(\"../data/submission_ridge_v4.csv\", index=False)\n",
    "print(\"✅ submission_ridge_v4.csv\")\n",
    "\n",
    "# Soumission 3: XGBoost très régularisé\n",
    "sub_xgb = template.copy()\n",
    "for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=30, max_depth=2, learning_rate=0.05,\n",
    "        reg_alpha=10, reg_lambda=10, subsample=0.6,\n",
    "        random_state=42, n_jobs=-1, verbosity=0\n",
    "    )\n",
    "    xgb_model.fit(X_train, y_train[target])\n",
    "    pred = np.maximum(xgb_model.predict(X_test), 0)\n",
    "    sub_xgb[target] = pred\n",
    "sub_xgb.to_csv(\"../data/submission_xgb_regularized_v4.csv\", index=False)\n",
    "print(\"✅ submission_xgb_regularized_v4.csv\")\n",
    "\n",
    "print(\"\\n3 fichiers créés dans ../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "compare-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparaison des prédictions\n",
      "============================================================\n",
      "\n",
      "Moyennes des prédictions par soumission :\n",
      "\n",
      "Ensemble:\n",
      "  Alkalinity: 93.7\n",
      "  Conductivity: 328.4\n",
      "  Phosphorus: 24.7\n",
      "\n",
      "Ridge:\n",
      "  Alkalinity: 92.7\n",
      "  Conductivity: 361.9\n",
      "  Phosphorus: 22.9\n",
      "\n",
      "XGBoost reg.:\n",
      "  Alkalinity: 102.2\n",
      "  Conductivity: 359.9\n",
      "  Phosphorus: 32.5\n",
      "\n",
      "Vraies valeurs (training) :\n",
      "  Alkalinity: 119.1\n",
      "  Conductivity: 485.0\n",
      "  Phosphorus: 43.5\n"
     ]
    }
   ],
   "source": [
    "# Comparer les prédictions\n",
    "print(\"Comparaison des prédictions\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nMoyennes des prédictions par soumission :\")\n",
    "for name, sub in [('Ensemble', sub_ensemble), ('Ridge', sub_ridge), ('XGBoost reg.', sub_xgb)]:\n",
    "    print(f\"\\n{name}:\")\n",
    "    for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "        print(f\"  {target_name}: {sub[target].mean():.1f}\")\n",
    "\n",
    "# Comparaison avec les vraies valeurs du training\n",
    "print(\"\\nVraies valeurs (training) :\")\n",
    "for target, target_name in zip(TARGET_COLS, TARGET_NAMES):\n",
    "    print(f\"  {target_name}: {y_train[target].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "## Résumé\n",
    "\n",
    "### Stratégie\n",
    "\n",
    "1. **Features** : Uniquement celles avec corrélation géographique < 0.10\n",
    "2. **Modèles** : Ridge, XGBoost, LightGBM très régularisés\n",
    "3. **Ensemble** : Moyenne des 3 modèles\n",
    "\n",
    "### Fichiers créés\n",
    "\n",
    "- `submission_ensemble_v4.csv` - Moyenne des 3 modèles\n",
    "- `submission_ridge_v4.csv` - Ridge seul (modèle linéaire)\n",
    "- `submission_xgb_regularized_v4.csv` - XGBoost très régularisé\n",
    "\n",
    "### À tester\n",
    "\n",
    "Soumettre les 3 fichiers et comparer avec le score de 0.05 de la version précédente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
