{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616441fc-62fd-43c9-961d-5b4606d02a3a",
   "metadata": {},
   "source": [
    "# ESA WorldCover - Extraction des Donn√©es d'Occupation du Sol\n",
    "\n",
    "## C'est quoi ESA WorldCover ?\n",
    "\n",
    "**ESA WorldCover** est une carte mondiale d'occupation du sol produite par l'Agence Spatiale Europ√©enne :\n",
    "- R√©solution spatiale de **10 m√®tres** (tr√®s pr√©cise !)\n",
    "- Bas√©e sur les images **Sentinel-1 et Sentinel-2**\n",
    "- **11 classes** d'occupation du sol\n",
    "\n",
    "## Pourquoi c'est utile pour la qualit√© de l'eau ?\n",
    "\n",
    "L'occupation du sol autour d'un point d'eau affecte directement sa qualit√© :\n",
    "\n",
    "| Occupation du sol | Impact sur la qualit√© de l'eau |\n",
    "|-------------------|--------------------------------|\n",
    "| **Zones agricoles** | Ruissellement d'engrais ‚Üí ‚Üë Phosphore |\n",
    "| **Zones urbaines** | Pollution, ruissellement imperm√©able ‚Üí ‚Üë Conductivit√© |\n",
    "| **For√™ts** | Filtration naturelle ‚Üí ‚Üì Pollution |\n",
    "| **Zones humides** | Absorption des nutriments ‚Üí ‚Üì Phosphore |\n",
    "| **Sol nu** | √ârosion ‚Üí ‚Üë Turbidit√©, s√©diments |\n",
    "\n",
    "## Ce que fait ce notebook\n",
    "\n",
    "```\n",
    "1. Se connecter √† l'API Microsoft Planetary Computer\n",
    "         ‚Üì\n",
    "2. Pour chaque site de mesure d'eau :\n",
    "   - D√©finir un buffer de 500m autour du point\n",
    "   - T√©l√©charger la tuile ESA WorldCover correspondante\n",
    "   - Calculer le pourcentage de chaque classe d'occupation\n",
    "         ‚Üì\n",
    "3. Sauvegarder le fichier CSV avec les features d'occupation du sol\n",
    "```\n",
    "\n",
    "## Classes ESA WorldCover\n",
    "\n",
    "| Code | Classe | Description |\n",
    "|------|--------|-------------|\n",
    "| 10 | Tree cover | For√™ts, arbres |\n",
    "| 20 | Shrubland | Arbustes |\n",
    "| 30 | Grassland | Prairies, herbages |\n",
    "| 40 | Cropland | Zones agricoles |\n",
    "| 50 | Built-up | Zones urbaines |\n",
    "| 60 | Bare / sparse vegetation | Sol nu, v√©g√©tation clairsem√©e |\n",
    "| 70 | Snow and ice | Neige et glace |\n",
    "| 80 | Permanent water bodies | Plans d'eau permanents |\n",
    "| 90 | Herbaceous wetland | Zones humides herbac√©es |\n",
    "| 95 | Mangroves | Mangroves |\n",
    "| 100 | Moss and lichen | Mousse et lichen |\n",
    "\n",
    "## Source des donn√©es\n",
    "\n",
    "Documentation : [ESA WorldCover sur Planetary Computer](https://planetarycomputer.microsoft.com/dataset/esa-worldcover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd7a3f-872e-4e04-8267-5d2c1ef4bcf4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 : Installation des d√©pendances\n",
    "\n",
    "**Premi√®re ex√©cution uniquement** : Apr√®s avoir ex√©cut√© cette cellule, il faut red√©marrer le kernel :\n",
    "1. Cliquer sur \"Connected\" en haut\n",
    "2. S√©lectionner \"Restart kernel\"\n",
    "\n",
    "Les ex√©cutions suivantes n'ont pas besoin de ce red√©marrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba9c9092-a1e5-410b-95cd-568e8bcca686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: uv in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (0.9.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.13.1 environment at: c:\\Program Files\\Python313\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m194 packages\u001b[0m \u001b[2min 4.33s\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to install: jupyter_events-0.12.0-py3-none-any.whl (jupyter-events==0.12.0)\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to create directory `c:\\Program Files\\Python313\\Lib\\site-packages\\jupyter_events`: Acc√®s refus√©. (os error 5)\n"
     ]
    }
   ],
   "source": [
    "!pip install uv\n",
    "!uv pip install --system -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35f9d94d-ecc7-45bf-812d-05d62f3b42d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Manipulation de donn√©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manipulation d'images raster\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "# Acc√®s √† l'API Microsoft Planetary Computer\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "from tqdm import tqdm  # Barre de progression\n",
    "import os\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74652f9-d132-4bd2-b444-beabc82fbeb0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 : D√©finition des constantes et fonctions\n",
    "\n",
    "### Classes ESA WorldCover\n",
    "\n",
    "On d√©finit les classes et leurs noms pour les colonnes du CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad324597-e798-4127-8668-da9ab6873467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes WorldCover : ['lc_tree', 'lc_shrubland', 'lc_grassland', 'lc_cropland', 'lc_builtup', 'lc_bare', 'lc_snow', 'lc_water', 'lc_wetland', 'lc_mangroves', 'lc_moss']\n",
      "Buffer : 500m autour de chaque point\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONSTANTES\n",
    "# =============================================================================\n",
    "\n",
    "# Classes ESA WorldCover (code ‚Üí nom de la feature)\n",
    "WORLDCOVER_CLASSES = {\n",
    "    10: 'lc_tree',        # Tree cover\n",
    "    20: 'lc_shrubland',   # Shrubland\n",
    "    30: 'lc_grassland',   # Grassland\n",
    "    40: 'lc_cropland',    # Cropland\n",
    "    50: 'lc_builtup',     # Built-up\n",
    "    60: 'lc_bare',        # Bare / sparse vegetation\n",
    "    70: 'lc_snow',        # Snow and ice\n",
    "    80: 'lc_water',       # Permanent water bodies\n",
    "    90: 'lc_wetland',     # Herbaceous wetland\n",
    "    95: 'lc_mangroves',   # Mangroves\n",
    "    100: 'lc_moss',       # Moss and lichen\n",
    "}\n",
    "\n",
    "# Taille du buffer autour de chaque point (en m√®tres)\n",
    "# 500m = on analyse l'occupation du sol dans un rayon de 500m autour du site\n",
    "BUFFER_SIZE_METERS = 500\n",
    "\n",
    "# Dossier de sortie\n",
    "OUTPUT_DIR = \"../data/processed\"\n",
    "\n",
    "print(f\"Classes WorldCover : {list(WORLDCOVER_CLASSES.values())}\")\n",
    "print(f\"Buffer : {BUFFER_SIZE_METERS}m autour de chaque point\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d42366-3ab5-47b4-bf86-32bb9c63eb7a",
   "metadata": {},
   "source": [
    "### Fonction : Connexion au catalogue Planetary Computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "connect-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_worldcover_catalog():\n",
    "    \"\"\"\n",
    "    Se connecte au catalogue Microsoft Planetary Computer et\n",
    "    retourne l'acc√®s √† la collection ESA WorldCover.\n",
    "    \"\"\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=pc.sign_inplace,\n",
    "    )\n",
    "    print(\"Connexion au catalogue Planetary Computer OK!\")\n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cd1bc1-0c50-4fee-926c-459927f397e2",
   "metadata": {},
   "source": [
    "### Fonction : Calculer un buffer en degr√©s\n",
    "\n",
    "Les coordonn√©es sont en degr√©s (lat/lon), mais on veut un buffer en m√®tres.\n",
    "On utilise une approximation simple :\n",
    "- 1 degr√© de latitude ‚âà 111 km\n",
    "- 1 degr√© de longitude ‚âà 111 km √ó cos(latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "buffer-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def meters_to_degrees(lat, meters):\n",
    "    \"\"\"\n",
    "    Convertit une distance en m√®tres en degr√©s.\n",
    "    \n",
    "    Param√®tres:\n",
    "        lat : latitude du point (pour ajuster la longitude)\n",
    "        meters : distance en m√®tres\n",
    "    \n",
    "    Retourne:\n",
    "        (delta_lat, delta_lon) en degr√©s\n",
    "    \"\"\"\n",
    "    # 1 degr√© de latitude ‚âà 111 km\n",
    "    delta_lat = meters / 111000\n",
    "    \n",
    "    # 1 degr√© de longitude d√©pend de la latitude\n",
    "    delta_lon = meters / (111000 * np.cos(np.radians(lat)))\n",
    "    \n",
    "    return delta_lat, delta_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1a70cf-cfdb-4256-808d-087d591e806f",
   "metadata": {},
   "source": [
    "### Fonction : Extraire les pourcentages d'occupation du sol\n",
    "\n",
    "Pour chaque site, on :\n",
    "1. Trouve la tuile ESA WorldCover qui couvre le point\n",
    "2. D√©coupe un buffer de 500m autour du point\n",
    "3. Compte les pixels de chaque classe\n",
    "4. Calcule le pourcentage de chaque classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extract-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landcover_percentages(catalog, lat, lon, buffer_meters=500, debug=False):\n",
    "    \"\"\"\n",
    "    Extrait les pourcentages de chaque classe d'occupation du sol\n",
    "    dans un buffer autour d'un point.\n",
    "    \n",
    "    Param√®tres:\n",
    "        catalog : catalogue Planetary Computer connect√©\n",
    "        lat, lon : coordonn√©es du point\n",
    "        buffer_meters : rayon du buffer en m√®tres\n",
    "        debug : afficher les messages de d√©bogage\n",
    "    \n",
    "    Retourne:\n",
    "        dict avec le pourcentage de chaque classe (0-100)\n",
    "    \"\"\"\n",
    "    # Initialiser les r√©sultats √† 0\n",
    "    results = {name: 0.0 for name in WORLDCOVER_CLASSES.values()}\n",
    "    \n",
    "    try:\n",
    "        # Calculer le buffer en degr√©s\n",
    "        delta_lat, delta_lon = meters_to_degrees(lat, buffer_meters)\n",
    "        \n",
    "        # Bounding box autour du point\n",
    "        bbox = [\n",
    "            lon - delta_lon,  # min lon\n",
    "            lat - delta_lat,  # min lat\n",
    "            lon + delta_lon,  # max lon\n",
    "            lat + delta_lat,  # max lat\n",
    "        ]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Bbox: {bbox}\")\n",
    "        \n",
    "        # Rechercher les tuiles ESA WorldCover qui couvrent ce point\n",
    "        # Note: On enl√®ve le filtre de version qui peut poser probl√®me\n",
    "        search = catalog.search(\n",
    "            collections=[\"esa-worldcover\"],\n",
    "            bbox=bbox,\n",
    "        )\n",
    "        items = list(search.items())\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Items trouv√©s: {len(items)}\")\n",
    "        \n",
    "        if len(items) == 0:\n",
    "            if debug:\n",
    "                print(\"  ‚ö†Ô∏è Pas de donn√©es pour ce point\")\n",
    "            return results\n",
    "        \n",
    "        # Prendre le premier item (le plus r√©cent)\n",
    "        item = items[0]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Item: {item.id}\")\n",
    "            print(f\"  Assets disponibles: {list(item.assets.keys())}\")\n",
    "        \n",
    "        # Signer l'asset pour l'acc√®s\n",
    "        signed_asset = pc.sign(item.assets[\"map\"])\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  URL sign√©e: {signed_asset.href[:80]}...\")\n",
    "        \n",
    "        # Ouvrir le raster et extraire la fen√™tre\n",
    "        with rasterio.open(signed_asset.href) as src:\n",
    "            if debug:\n",
    "                print(f\"  CRS du raster: {src.crs}\")\n",
    "                print(f\"  Bounds du raster: {src.bounds}\")\n",
    "            \n",
    "            # Transformer la bbox dans le CRS du raster\n",
    "            dst_crs = src.crs\n",
    "            transformed_bbox = transform_bounds(\n",
    "                CRS.from_epsg(4326),  # WGS84 (lat/lon)\n",
    "                dst_crs,\n",
    "                *bbox\n",
    "            )\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Bbox transform√©e: {transformed_bbox}\")\n",
    "            \n",
    "            # Cr√©er une fen√™tre de lecture\n",
    "            window = from_bounds(*transformed_bbox, src.transform)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Window: {window}\")\n",
    "            \n",
    "            # Lire les donn√©es\n",
    "            data = src.read(1, window=window)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Shape des donn√©es: {data.shape}\")\n",
    "                print(f\"  Valeurs uniques: {np.unique(data)}\")\n",
    "            \n",
    "            if data.size == 0:\n",
    "                if debug:\n",
    "                    print(\"  ‚ö†Ô∏è Donn√©es vides\")\n",
    "                return results\n",
    "            \n",
    "            # Compter les pixels de chaque classe\n",
    "            total_pixels = data.size\n",
    "            unique, counts = np.unique(data, return_counts=True)\n",
    "            \n",
    "            for class_code, class_name in WORLDCOVER_CLASSES.items():\n",
    "                if class_code in unique:\n",
    "                    idx = np.where(unique == class_code)[0][0]\n",
    "                    results[class_name] = (counts[idx] / total_pixels) * 100\n",
    "        \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"  ‚ùå Erreur: {type(e).__name__}: {e}\")\n",
    "        # En cas d'erreur, on retourne des 0\n",
    "        pass\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ekt0yl5vawj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de diagnostic ESA WorldCover\n",
      "==================================================\n",
      "Connexion au catalogue Planetary Computer OK!\n",
      "\n",
      "Test avec le point: lat=-26.45, lon=28.085833\n",
      "--------------------------------------------------\n",
      "  Bbox: [np.float64(28.08080185204243), -26.454504504504502, np.float64(28.09086414795757), -26.445495495495496]\n",
      "  Items trouv√©s: 2\n",
      "  Item: ESA_WorldCover_10m_2021_v200_S27E027\n",
      "  Assets disponibles: ['map', 'input_quality', 'tilejson', 'rendered_preview']\n",
      "  URL sign√©e: https://ai4edataeuwest.blob.core.windows.net/esa-worldcover/v200/2021/map/ESA_Wo...\n",
      "  CRS du raster: EPSG:4326\n",
      "  Bounds du raster: BoundingBox(left=27.0, bottom=-27.0, right=30.0, top=-24.0)\n",
      "  Bbox transform√©e: (28.08080185204243, -26.454504504504502, 28.09086414795757, -26.445495495495496)\n",
      "  Window: Window(col_off=np.float64(12969.622224509167), row_off=np.float64(29345.945945945958), width=np.float64(120.74755098169044), height=np.float64(108.10810810807016))\n",
      "  Shape des donn√©es: (108, 121)\n",
      "  Valeurs uniques: [10 30 40 50 60 80]\n",
      "\n",
      "R√©sultats:\n",
      "  lc_tree: 2.8%\n",
      "  lc_grassland: 47.5%\n",
      "  lc_cropland: 46.6%\n",
      "  lc_builtup: 1.5%\n",
      "  lc_bare: 0.1%\n",
      "  lc_water: 1.5%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST DE DIAGNOSTIC - Ex√©cuter cette cellule pour voir pourquoi les donn√©es sont √† 0\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Test de diagnostic ESA WorldCover\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Se connecter au catalogue\n",
    "catalog = get_worldcover_catalog()\n",
    "\n",
    "# Tester avec un point en Afrique du Sud\n",
    "test_lat, test_lon = -26.45, 28.085833  # Un point du dataset\n",
    "\n",
    "print(f\"\\nTest avec le point: lat={test_lat}, lon={test_lon}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Extraire avec debug activ√©\n",
    "result = extract_landcover_percentages(catalog, test_lat, test_lon, 500, debug=True)\n",
    "\n",
    "print(\"\\nR√©sultats:\")\n",
    "for k, v in result.items():\n",
    "    if v > 0:\n",
    "        print(f\"  {k}: {v:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8065c081-51ca-439e-b42d-fa1afcb961e9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 : Extraction pour les donn√©es d'entra√Ænement\n",
    "\n",
    "On applique la fonction √† tous les sites de mesure du dataset d'entra√Ænement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54291642-9b6a-42a5-8370-12c230b755d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sites : 9319\n",
      "Colonnes : ['Latitude', 'Longitude', 'Sample Date', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  02-01-2011           128.912                   555.0   \n",
       "1 -26.861111  28.884722  03-01-2011            74.720                   162.9   \n",
       "2 -26.450000  28.085833  03-01-2011            89.254                   573.0   \n",
       "3 -27.671111  27.236944  03-01-2011            82.000                   203.6   \n",
       "4 -27.356667  27.286389  03-01-2011            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                           10.0  \n",
       "1                          163.0  \n",
       "2                           80.0  \n",
       "3                          101.0  \n",
       "4                          151.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger les donn√©es de qualit√© d'eau (nos sites de mesure)\n",
    "Water_Quality_df = pd.read_csv(\"../data/raw/water_quality_training_dataset.csv\")\n",
    "\n",
    "print(f\"Nombre de sites : {len(Water_Quality_df)}\")\n",
    "print(f\"Colonnes : {list(Water_Quality_df.columns)}\")\n",
    "display(Water_Quality_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "unique-sites-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites uniques √† traiter : 162\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les sites uniques (lat/lon)\n",
    "# On n'a pas besoin d'extraire plusieurs fois pour le m√™me site\n",
    "training_sites = Water_Quality_df[['Latitude', 'Longitude']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Sites uniques √† traiter : {len(training_sites)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "34229a57-1579-4615-8b07-64fde8299e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion √† Microsoft Planetary Computer...\n",
      "Connexion au catalogue Planetary Computer OK!\n",
      "\n",
      "Extraction pour 162 sites uniques...\n",
      "Buffer : 500m autour de chaque point\n",
      "Sauvegarde automatique tous les 50 sites ‚Üí ../data/processed/worldcover_training_backup.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction:  31%|‚ñà‚ñà‚ñà‚ñè      | 51/162 [00:12<00:22,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde : 50/162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/162 [00:24<00:16,  3.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde : 100/162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 150/162 [00:34<00:03,  3.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde : 150/162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [00:37<00:00,  4.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction termin√©e : 162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION ESA WORLDCOVER - TRAINING (avec sauvegarde incr√©mentale)\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Connexion √† Microsoft Planetary Computer...\")\n",
    "catalog = get_worldcover_catalog()\n",
    "\n",
    "print(f\"\\nExtraction pour {len(training_sites)} sites uniques...\")\n",
    "print(f\"Buffer : {BUFFER_SIZE_METERS}m autour de chaque point\")\n",
    "\n",
    "# Fichier de sauvegarde incr√©mentale\n",
    "BACKUP_PATH = \"../data/processed/worldcover_training_backup.csv\"\n",
    "SAVE_EVERY = 50  # Sauvegarder tous les 50 sites\n",
    "\n",
    "print(f\"Sauvegarde automatique tous les {SAVE_EVERY} sites ‚Üí {BACKUP_PATH}\\n\")\n",
    "\n",
    "# Liste pour stocker les r√©sultats\n",
    "training_results = []\n",
    "completed_count = 0\n",
    "\n",
    "for idx, row in tqdm(training_sites.iterrows(), total=len(training_sites), desc=\"Extraction\"):\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    \n",
    "    # Extraire les pourcentages\n",
    "    lc_percentages = extract_landcover_percentages(catalog, lat, lon, BUFFER_SIZE_METERS)\n",
    "    \n",
    "    # Ajouter les coordonn√©es\n",
    "    result = {'Latitude': lat, 'Longitude': lon}\n",
    "    result.update(lc_percentages)\n",
    "    \n",
    "    training_results.append(result)\n",
    "    completed_count += 1\n",
    "    \n",
    "    # Sauvegarde incr√©mentale\n",
    "    if completed_count % SAVE_EVERY == 0:\n",
    "        backup_df = pd.DataFrame(training_results)\n",
    "        backup_df.to_csv(BACKUP_PATH, index=False)\n",
    "        print(f\"\\nüíæ Sauvegarde : {completed_count}/{len(training_sites)} sites\")\n",
    "\n",
    "# Sauvegarde finale\n",
    "training_landcover_unique = pd.DataFrame(training_results)\n",
    "training_landcover_unique.to_csv(BACKUP_PATH, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction termin√©e : {len(training_landcover_unique)} sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "merge-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final : 9319 lignes\n"
     ]
    }
   ],
   "source": [
    "# Fusionner avec le DataFrame original pour avoir une ligne par observation\n",
    "# (plusieurs observations peuvent correspondre au m√™me site √† des dates diff√©rentes)\n",
    "training_landcover_df = Water_Quality_df[['Latitude', 'Longitude', 'Sample Date']].merge(\n",
    "    training_landcover_unique,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"DataFrame final : {len(training_landcover_df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c2eebd3-78ab-4306-ba51-57542dee97bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√© : ../data/processed\\worldcover_features_training.csv\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le fichier CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'worldcover_features_training.csv')\n",
    "training_landcover_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier cr√©√© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c2114e6-8204-4cf7-8f0d-16745cb1fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es extraites :\n",
      "- Lignes : 9319\n",
      "- Colonnes : ['Latitude', 'Longitude', 'Sample Date', 'lc_tree', 'lc_shrubland', 'lc_grassland', 'lc_cropland', 'lc_builtup', 'lc_bare', 'lc_snow', 'lc_water', 'lc_wetland', 'lc_mangroves', 'lc_moss']\n",
      "\n",
      "Statistiques des classes d'occupation du sol (% moyen) :\n",
      "  lc_grassland: 39.5%\n",
      "  lc_tree: 18.4%\n",
      "  lc_shrubland: 16.1%\n",
      "  lc_cropland: 15.9%\n",
      "  lc_water: 4.1%\n",
      "  lc_builtup: 4.0%\n",
      "  lc_bare: 1.9%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>lc_tree</th>\n",
       "      <th>lc_shrubland</th>\n",
       "      <th>lc_grassland</th>\n",
       "      <th>lc_cropland</th>\n",
       "      <th>lc_builtup</th>\n",
       "      <th>lc_bare</th>\n",
       "      <th>lc_snow</th>\n",
       "      <th>lc_water</th>\n",
       "      <th>lc_wetland</th>\n",
       "      <th>lc_mangroves</th>\n",
       "      <th>lc_moss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>9.131286</td>\n",
       "      <td>11.683228</td>\n",
       "      <td>0.910870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.721168</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.553448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>3.359351</td>\n",
       "      <td>0.038261</td>\n",
       "      <td>35.146924</td>\n",
       "      <td>61.072850</td>\n",
       "      <td>0.374962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>2.816039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>47.520661</td>\n",
       "      <td>46.640649</td>\n",
       "      <td>1.469238</td>\n",
       "      <td>0.053566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.499847</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>26.191560</td>\n",
       "      <td>0.091075</td>\n",
       "      <td>29.622040</td>\n",
       "      <td>4.401943</td>\n",
       "      <td>32.741348</td>\n",
       "      <td>0.159381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.792653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>5.297511</td>\n",
       "      <td>0.075896</td>\n",
       "      <td>70.332423</td>\n",
       "      <td>22.715543</td>\n",
       "      <td>1.555859</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date    lc_tree  lc_shrubland  lc_grassland  \\\n",
       "0 -28.760833  17.730278  02-01-2011   9.131286     11.683228      0.910870   \n",
       "1 -26.861111  28.884722  03-01-2011   3.359351      0.038261     35.146924   \n",
       "2 -26.450000  28.085833  03-01-2011   2.816039      0.000000     47.520661   \n",
       "3 -27.671111  27.236944  03-01-2011  26.191560      0.091075     29.622040   \n",
       "4 -27.356667  27.286389  03-01-2011   5.297511      0.075896     70.332423   \n",
       "\n",
       "   lc_cropland  lc_builtup    lc_bare  lc_snow   lc_water  lc_wetland  \\\n",
       "0     0.000000    0.000000  55.721168      0.0  22.553448         0.0   \n",
       "1    61.072850    0.374962   0.000000      0.0   0.007652         0.0   \n",
       "2    46.640649    1.469238   0.053566      0.0   1.499847         0.0   \n",
       "3     4.401943   32.741348   0.159381      0.0   6.792653         0.0   \n",
       "4    22.715543    1.555859   0.000000      0.0   0.022769         0.0   \n",
       "\n",
       "   lc_mangroves  lc_moss  \n",
       "0           0.0      0.0  \n",
       "1           0.0      0.0  \n",
       "2           0.0      0.0  \n",
       "3           0.0      0.0  \n",
       "4           0.0      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aper√ßu du fichier cr√©√©\n",
    "print(\"Aper√ßu des donn√©es extraites :\")\n",
    "print(f\"- Lignes : {len(training_landcover_df)}\")\n",
    "print(f\"- Colonnes : {list(training_landcover_df.columns)}\")\n",
    "\n",
    "# Colonnes d'occupation du sol\n",
    "lc_cols = list(WORLDCOVER_CLASSES.values())\n",
    "\n",
    "print(f\"\\nStatistiques des classes d'occupation du sol (% moyen) :\")\n",
    "stats = training_landcover_df[lc_cols].mean().sort_values(ascending=False)\n",
    "for col, val in stats.items():\n",
    "    if val > 0.1:  # Afficher seulement les classes > 0.1%\n",
    "        print(f\"  {col}: {val:.1f}%\")\n",
    "\n",
    "display(training_landcover_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91cf806-2228-4b46-a0c1-8b1afb01bc6d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 : Extraction pour les donn√©es de validation\n",
    "\n",
    "M√™me processus pour les donn√©es de **validation** (`submission_template.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ed3f63d-3a89-4145-b2a6-917c2e98fa4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sites de validation : 200\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -32.043333  27.822778  01-09-2014               NaN                     NaN   \n",
       "1 -33.329167  26.077500  16-09-2015               NaN                     NaN   \n",
       "2 -32.991639  27.640028  07-05-2015               NaN                     NaN   \n",
       "3 -34.096389  24.439167  07-02-2012               NaN                     NaN   \n",
       "4 -32.000556  28.581667  01-10-2014               NaN                     NaN   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                            NaN  \n",
       "1                            NaN  \n",
       "2                            NaN  \n",
       "3                            NaN  \n",
       "4                            NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger le template de soumission (sites de validation)\n",
    "Validation_df = pd.read_csv('../data/raw/submission_template.csv')\n",
    "\n",
    "print(f\"Nombre de sites de validation : {len(Validation_df)}\")\n",
    "display(Validation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "unique-sites-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sites uniques √† traiter : 24\n"
     ]
    }
   ],
   "source": [
    "# Obtenir les sites uniques\n",
    "validation_sites = Validation_df[['Latitude', 'Longitude']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Sites uniques √† traiter : {len(validation_sites)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4a6c090-39df-4923-b03b-1fc257e2952b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction pour 24 sites uniques...\n",
      "Sauvegarde automatique tous les 20 sites ‚Üí ../data/processed/worldcover_validation_backup.csv\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 20/24 [00:03<00:00,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde : 20/24 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:04<00:00,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction termin√©e : 24 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION ESA WORLDCOVER - VALIDATION (avec sauvegarde incr√©mentale)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Extraction pour {len(validation_sites)} sites uniques...\")\n",
    "\n",
    "# Fichier de sauvegarde incr√©mentale\n",
    "BACKUP_PATH_VAL = \"../data/processed/worldcover_validation_backup.csv\"\n",
    "SAVE_EVERY_VAL = 20  # Sauvegarder tous les 20 sites\n",
    "\n",
    "print(f\"Sauvegarde automatique tous les {SAVE_EVERY_VAL} sites ‚Üí {BACKUP_PATH_VAL}\\n\")\n",
    "\n",
    "# Liste pour stocker les r√©sultats\n",
    "validation_results = []\n",
    "completed_count = 0\n",
    "\n",
    "for idx, row in tqdm(validation_sites.iterrows(), total=len(validation_sites), desc=\"Extraction\"):\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    \n",
    "    # Extraire les pourcentages\n",
    "    lc_percentages = extract_landcover_percentages(catalog, lat, lon, BUFFER_SIZE_METERS)\n",
    "    \n",
    "    # Ajouter les coordonn√©es\n",
    "    result = {'Latitude': lat, 'Longitude': lon}\n",
    "    result.update(lc_percentages)\n",
    "    \n",
    "    validation_results.append(result)\n",
    "    completed_count += 1\n",
    "    \n",
    "    # Sauvegarde incr√©mentale\n",
    "    if completed_count % SAVE_EVERY_VAL == 0:\n",
    "        backup_df = pd.DataFrame(validation_results)\n",
    "        backup_df.to_csv(BACKUP_PATH_VAL, index=False)\n",
    "        print(f\"\\nüíæ Sauvegarde : {completed_count}/{len(validation_sites)} sites\")\n",
    "\n",
    "# Sauvegarde finale\n",
    "validation_landcover_unique = pd.DataFrame(validation_results)\n",
    "validation_landcover_unique.to_csv(BACKUP_PATH_VAL, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction termin√©e : {len(validation_landcover_unique)} sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "merge-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final : 200 lignes\n"
     ]
    }
   ],
   "source": [
    "# Fusionner avec le DataFrame original\n",
    "validation_landcover_df = Validation_df[['Latitude', 'Longitude', 'Sample Date']].merge(\n",
    "    validation_landcover_unique,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"DataFrame final : {len(validation_landcover_df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5f0fc36a-b4b7-44c4-bc59-7a1f6216d5ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√© : ../data/processed\\worldcover_features_validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le fichier CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'worldcover_features_validation.csv')\n",
    "validation_landcover_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier cr√©√© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "23777c24-0347-4b35-ae06-f53ead075493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es de validation : 200 lignes\n",
      "Colonnes : ['Latitude', 'Longitude', 'Sample Date', 'lc_tree', 'lc_shrubland', 'lc_grassland', 'lc_cropland', 'lc_builtup', 'lc_bare', 'lc_snow', 'lc_water', 'lc_wetland', 'lc_mangroves', 'lc_moss']\n",
      "\n",
      "Statistiques des classes d'occupation du sol (% moyen) :\n",
      "  lc_tree: 35.7%\n",
      "  lc_grassland: 27.5%\n",
      "  lc_shrubland: 21.4%\n",
      "  lc_cropland: 9.8%\n",
      "  lc_builtup: 2.5%\n",
      "  lc_water: 1.6%\n",
      "  lc_bare: 1.3%\n",
      "  lc_wetland: 0.1%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>lc_tree</th>\n",
       "      <th>lc_shrubland</th>\n",
       "      <th>lc_grassland</th>\n",
       "      <th>lc_cropland</th>\n",
       "      <th>lc_builtup</th>\n",
       "      <th>lc_bare</th>\n",
       "      <th>lc_snow</th>\n",
       "      <th>lc_water</th>\n",
       "      <th>lc_wetland</th>\n",
       "      <th>lc_mangroves</th>\n",
       "      <th>lc_moss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>6.394676</td>\n",
       "      <td>7.631655</td>\n",
       "      <td>70.392072</td>\n",
       "      <td>5.454282</td>\n",
       "      <td>6.604456</td>\n",
       "      <td>2.235243</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.287616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>73.327591</td>\n",
       "      <td>22.968705</td>\n",
       "      <td>2.627046</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.076658</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>61.663796</td>\n",
       "      <td>17.829457</td>\n",
       "      <td>17.915590</td>\n",
       "      <td>2.239449</td>\n",
       "      <td>0.100488</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>57.478089</td>\n",
       "      <td>6.184620</td>\n",
       "      <td>15.493356</td>\n",
       "      <td>20.794459</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049477</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>36.395451</td>\n",
       "      <td>35.739283</td>\n",
       "      <td>11.628755</td>\n",
       "      <td>0.627005</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>1.013415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.574220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date    lc_tree  lc_shrubland  lc_grassland  \\\n",
       "0 -32.043333  27.822778  01-09-2014   6.394676      7.631655     70.392072   \n",
       "1 -33.329167  26.077500  16-09-2015  73.327591     22.968705      2.627046   \n",
       "2 -32.991639  27.640028  07-05-2015  61.663796     17.829457     17.915590   \n",
       "3 -34.096389  24.439167  07-02-2012  57.478089      6.184620     15.493356   \n",
       "4 -32.000556  28.581667  01-10-2014  36.395451     35.739283     11.628755   \n",
       "\n",
       "   lc_cropland  lc_builtup   lc_bare  lc_snow   lc_water  lc_wetland  \\\n",
       "0     5.454282    6.604456  2.235243      0.0   1.287616         0.0   \n",
       "1     0.000000    1.076658  0.000000      0.0   0.000000         0.0   \n",
       "2     2.239449    0.100488  0.000000      0.0   0.251220         0.0   \n",
       "3    20.794459    0.000000  0.049477      0.0   0.000000         0.0   \n",
       "4     0.627005    0.021872  1.013415      0.0  14.574220         0.0   \n",
       "\n",
       "   lc_mangroves  lc_moss  \n",
       "0           0.0      0.0  \n",
       "1           0.0      0.0  \n",
       "2           0.0      0.0  \n",
       "3           0.0      0.0  \n",
       "4           0.0      0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aper√ßu des donn√©es de validation\n",
    "print(f\"Donn√©es de validation : {len(validation_landcover_df)} lignes\")\n",
    "print(f\"Colonnes : {list(validation_landcover_df.columns)}\")\n",
    "\n",
    "print(f\"\\nStatistiques des classes d'occupation du sol (% moyen) :\")\n",
    "stats = validation_landcover_df[lc_cols].mean().sort_values(ascending=False)\n",
    "for col, val in stats.items():\n",
    "    if val > 0.1:\n",
    "        print(f\"  {col}: {val:.1f}%\")\n",
    "\n",
    "display(validation_landcover_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b2806-b54b-4182-bf85-680f13edf181",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R√©sum√©\n",
    "\n",
    "**Ce qu'on a fait :**\n",
    "1. Connect√© √† Microsoft Planetary Computer\n",
    "2. Pour chaque site de mesure :\n",
    "   - D√©fini un buffer de 500m\n",
    "   - Extrait la carte ESA WorldCover 2021\n",
    "   - Calcul√© le pourcentage de chaque classe\n",
    "3. Cr√©√© 2 fichiers CSV avec les features d'occupation du sol\n",
    "\n",
    "**Features extraites :**\n",
    "\n",
    "| Feature | Classe ESA WorldCover |\n",
    "|---------|----------------------|\n",
    "| lc_tree | Couvert forestier |\n",
    "| lc_shrubland | Arbustes |\n",
    "| lc_grassland | Prairies |\n",
    "| lc_cropland | Zones agricoles |\n",
    "| lc_builtup | Zones urbaines |\n",
    "| lc_bare | Sol nu |\n",
    "| lc_water | Plans d'eau |\n",
    "| lc_wetland | Zones humides |\n",
    "\n",
    "**Fichiers cr√©√©s :**\n",
    "\n",
    "| Fichier | Description |\n",
    "|---------|-------------|\n",
    "| worldcover_features_training.csv | Features pour l'entra√Ænement |\n",
    "| worldcover_features_validation.csv | Features pour la validation |\n",
    "\n",
    "**Prochaine √©tape :**\n",
    "- Int√©grer ces features dans le mod√®le Random Forest\n",
    "- Voir si l'occupation du sol am√©liore les pr√©dictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
