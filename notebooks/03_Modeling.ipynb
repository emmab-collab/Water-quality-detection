{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 - Modélisation\n",
    "\n",
    "**Étapes:**\n",
    "1. Charger et préparer les données\n",
    "2. Split train/val/test (60/20/20)\n",
    "3. Normaliser (StandardScaler)\n",
    "4. Entraîner Random Forest\n",
    "5. Évaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.paths import WATER_QUALITY_FILE, LANDSAT_FILE, TERRACLIMATE_FILE\n",
    "from src.config import TARGETS, ALL_FEATURES\n",
    "from src.data.load_data import load_all\n",
    "from src.features import prepare_training, select_model_features\n",
    "from src.models import split_data, normalize, train_models, evaluate, print_results, get_feature_importance\n",
    "from src.visualization import plot_predictions, plot_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Charger et préparer les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger\n",
    "_, _, _, df_raw = load_all(\n",
    "    str(WATER_QUALITY_FILE),\n",
    "    str(LANDSAT_FILE),\n",
    "    str(TERRACLIMATE_FILE),\n",
    "    features=ALL_FEATURES,\n",
    "    fill_na=False\n",
    ")\n",
    "\n",
    "# Préparer (nettoyer + features + encoding)\n",
    "df_train, medians = prepare_training(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sélectionner X et y\n",
    "X = select_model_features(df_train)\n",
    "y = df_train[TARGETS]\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "print(f\"X: {X.shape}\")\n",
    "print(f\"y: {y.shape}\")\n",
    "print(f\"\\nFeatures: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 2. Split train/val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 3. Normaliser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc, X_val_sc, X_test_sc, scaler = normalize(X_train, X_val, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Entraîner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = train_models(X_train_sc, y_train, n_estimators=100, max_depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Évaluer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation\n",
    "val_results = evaluate(models, X_val_sc, y_val)\n",
    "print_results(val_results, \"VALIDATION\")\n",
    "\n",
    "# Test\n",
    "test_results = evaluate(models, X_test_sc, y_test)\n",
    "print_results(test_results, \"TEST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques prédictions vs réalité\n",
    "plot_predictions(models, X_test_sc, y_test, test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Importance des features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_importance(models, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 10 features par target\n",
    "importances = get_feature_importance(models, feature_names)\n",
    "for target, df in importances.items():\n",
    "    print(f\"\\n{target}:\")\n",
    "    print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
