{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 03 - Modélisation\n\n**Objectif** : Entraîner un modèle pour prédire la qualité de l'eau.\n\n---\n\n## Questions à se poser :\n1. Comment séparer les données pour évaluer correctement le modèle ?\n2. Faut-il normaliser les features ? Pourquoi ?\n3. Quels hyperparamètres choisir pour le Random Forest ?\n4. Comment interpréter les métriques R² et RMSE ?\n5. Quelles features sont les plus importantes pour chaque target ?\n\n---\n\n## Programme du notebook :\n1. Charger les données\n2. Séparer en train/test (70%/30%)\n3. Normaliser les features (StandardScaler)\n4. Entraîner un Random Forest pour chaque target\n5. Évaluer avec R² et RMSE\n6. Analyser l'importance des features\n7. Préparer le code pour la soumission"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Imports et chargement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.paths import WATER_QUALITY_FILE, LANDSAT_FILE, TERRACLIMATE_FILE\n",
    "from src.data.load_data import load_all\n",
    "from src.config import TARGETS, BENCHMARK_FEATURES, RANDOM_SEED, TEST_SIZE\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "X, y, site_ids, df = load_all(\n",
    "    str(WATER_QUALITY_FILE),\n",
    "    str(LANDSAT_FILE),\n",
    "    str(TERRACLIMATE_FILE)\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "print(f\"\\nFeatures utilisées: {list(X.columns)}\")\n",
    "print(f\"Targets: {list(y.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Séparation Train / Test\n",
    "\n",
    "On garde 30% des données pour tester notre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparer les données\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} lignes\")\n",
    "print(f\"Test: {len(X_test)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliser les features (mettre à la même échelle)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Features normalisées!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Entraîner un modèle Random Forest\n",
    "\n",
    "**Random Forest** = beaucoup d'arbres de décision qui \"votent\" ensemble.\n",
    "\n",
    "On entraîne un modèle séparé pour chaque target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionnaire pour stocker les modèles\n",
    "models = {}\n",
    "\n",
    "# Entraîner un modèle pour chaque target\n",
    "for target in TARGETS:\n",
    "    print(f\"\\nEntraînement pour: {target}\")\n",
    "    \n",
    "    # Créer le modèle\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=100,    # 100 arbres\n",
    "        max_depth=10,        # Profondeur max des arbres\n",
    "        random_state=RANDOM_SEED\n",
    "    )\n",
    "    \n",
    "    # Entraîner\n",
    "    model.fit(X_train_scaled, y_train[target])\n",
    "    \n",
    "    # Sauvegarder\n",
    "    models[target] = model\n",
    "    \n",
    "    print(f\"  -> Modèle entraîné!\")\n",
    "\n",
    "print(\"\\nTous les modèles sont prêts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Évaluer le modèle\n",
    "\n",
    "On utilise deux métriques :\n",
    "- **R²** : entre 0 et 1, plus c'est proche de 1, mieux c'est\n",
    "- **RMSE** : erreur moyenne, plus c'est petit, mieux c'est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Évaluer chaque modèle\n",
    "print(\"Résultats sur les données TEST :\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for target in TARGETS:\n",
    "    # Prédire\n",
    "    y_pred = models[target].predict(X_test_scaled)\n",
    "    y_true = y_test[target]\n",
    "    \n",
    "    # Calculer les métriques\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    \n",
    "    print(f\"\\n{target}:\")\n",
    "    print(f\"  R² = {r2:.3f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiser : Prédictions vs Valeurs réelles\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    y_pred = models[target].predict(X_test_scaled)\n",
    "    y_true = y_test[target]\n",
    "    \n",
    "    ax.scatter(y_true, y_pred, alpha=0.5)\n",
    "    \n",
    "    # Ligne parfaite (y_pred = y_true)\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='Parfait')\n",
    "    \n",
    "    ax.set_xlabel('Valeur réelle')\n",
    "    ax.set_ylabel('Prédiction')\n",
    "    ax.set_title(target)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Importance des features\n",
    "\n",
    "Quelles variables sont les plus utiles pour prédire ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher l'importance des features pour chaque target\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "for i, target in enumerate(TARGETS):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Récupérer les importances\n",
    "    importances = models[target].feature_importances_\n",
    "    feature_names = X.columns\n",
    "    \n",
    "    # Trier par importance\n",
    "    sorted_idx = np.argsort(importances)[::-1]\n",
    "    \n",
    "    # Afficher\n",
    "    ax.bar(range(len(importances)), importances[sorted_idx])\n",
    "    ax.set_xticks(range(len(importances)))\n",
    "    ax.set_xticklabels([feature_names[i] for i in sorted_idx], rotation=45, ha='right')\n",
    "    ax.set_title(target)\n",
    "    ax.set_ylabel('Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Créer une soumission\n",
    "\n",
    "Pour le challenge, on doit prédire sur de nouvelles données et créer un fichier CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple : créer une soumission (quand on aura les vraies données de test)\n",
    "\n",
    "# 1. Charger les données de test du challenge\n",
    "# test_df = pd.read_csv('path/to/test.csv')\n",
    "# X_test_challenge = test_df[BENCHMARK_FEATURES]\n",
    "# X_test_challenge_scaled = scaler.transform(X_test_challenge)\n",
    "\n",
    "# 2. Faire les prédictions\n",
    "# predictions = {}\n",
    "# for target in TARGETS:\n",
    "#     predictions[target] = models[target].predict(X_test_challenge_scaled)\n",
    "\n",
    "# 3. Créer le fichier de soumission\n",
    "# submission = pd.DataFrame(predictions)\n",
    "# submission.to_csv('../outputs/submissions/submission.csv', index=False)\n",
    "\n",
    "print(\"Le code est prêt pour créer une soumission!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Résumé et prochaines étapes\n",
    "\n",
    "### Ce qu'on a fait :\n",
    "- Séparé les données en train/test\n",
    "- Entraîné un Random Forest pour chaque target\n",
    "- Évalué avec R² et RMSE\n",
    "- Visualisé les prédictions et l'importance des features\n",
    "\n",
    "### Pour améliorer le modèle :\n",
    "1. **Plus de features** : ajouter les features créées dans le notebook 02\n",
    "2. **Autres modèles** : tester LightGBM, XGBoost\n",
    "3. **Tuning** : ajuster les hyperparamètres (n_estimators, max_depth...)\n",
    "4. **Validation croisée** : utiliser `cross_val_score` pour une évaluation plus robuste"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}