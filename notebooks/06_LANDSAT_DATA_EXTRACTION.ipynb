{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-landsat",
   "metadata": {},
   "source": [
    "# Landsat - Extraction des DonnÃ©es Satellitaires\n",
    "\n",
    "## C'est quoi Landsat ?\n",
    "\n",
    "**Landsat** est un programme de satellites d'observation de la Terre (NASA/USGS) :\n",
    "- Des images depuis **1972** (le plus ancien programme satellite civil)\n",
    "- Une rÃ©solution spatiale de **30 mÃ¨tres**\n",
    "- Des images tous les **16 jours** pour un mÃªme lieu\n",
    "- Plusieurs **bandes spectrales** (visible, infrarouge, etc.)\n",
    "\n",
    "## Pourquoi on en a besoin ?\n",
    "\n",
    "Les images satellite permettent de **voir** l'Ã©tat de l'eau et de son environnement :\n",
    "- **Bande verte (Green)** â†’ DÃ©tecte la turbiditÃ© et les algues\n",
    "- **Bande NIR (proche infrarouge)** â†’ Distingue l'eau de la vÃ©gÃ©tation\n",
    "- **Bandes SWIR (infrarouge Ã  ondes courtes)** â†’ DÃ©tecte l'humiditÃ© et les minÃ©raux\n",
    "\n",
    "## Ce que fait ce notebook\n",
    "\n",
    "```\n",
    "1. Se connecter Ã  l'API Microsoft Planetary Computer\n",
    "         â†“\n",
    "2. Pour chaque site de mesure d'eau :\n",
    "   - Chercher l'image Landsat la plus proche en date\n",
    "   - Filtrer les images avec peu de nuages (<10%)\n",
    "   - Extraire les valeurs spectrales (buffer de 100m)\n",
    "         â†“\n",
    "3. Calculer les indices spectraux (NDMI, MNDWI)\n",
    "         â†“\n",
    "4. Sauvegarder le fichier CSV avec les features Landsat\n",
    "```\n",
    "\n",
    "## DiffÃ©rence avec TerraClimate\n",
    "\n",
    "| Aspect | TerraClimate | Landsat |\n",
    "|--------|--------------|----------|\n",
    "| Type | DonnÃ©es climatiques (grille) | Images satellite (scÃ¨nes) |\n",
    "| Format | Zarr (chargement rapide) | ScÃ¨nes individuelles (API) |\n",
    "| RÃ©solution | ~4 km | 30 m |\n",
    "| Temps d'exÃ©cution | ~5 minutes | ~2-7 heures |\n",
    "\n",
    "âš ï¸ **Note importante** : Contrairement Ã  TerraClimate, Landsat nÃ©cessite des appels API individuels pour chaque point. Le traitement est donc plus lent mais peut Ãªtre parallÃ©lisÃ©.\n",
    "\n",
    "## Source des donnÃ©es\n",
    "\n",
    "Documentation : [Landsat Collection 2 Level 2 sur Planetary Computer](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-install",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ã‰tape 1 : Installation des dÃ©pendances\n",
    "\n",
    "**PremiÃ¨re exÃ©cution uniquement** : AprÃ¨s avoir exÃ©cutÃ© cette cellule, il faut redÃ©marrer le kernel :\n",
    "1. Cliquer sur \"Connected\" en haut\n",
    "2. SÃ©lectionner \"Restart kernel\"\n",
    "\n",
    "Les exÃ©cutions suivantes n'ont pas besoin de ce redÃ©marrage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: uv in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (0.9.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\u001b[2mUsing Python 3.13.1 environment at: c:\\Program Files\\Python313\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m194 packages\u001b[0m \u001b[2min 6.14s\u001b[0m\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pygments \u001b[2m(1.2MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m lxml \u001b[2m(3.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m xarray \u001b[2m(1.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m debugpy \u001b[2m(5.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m shapely \u001b[2m(1.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pywinpty \u001b[2m(2.0MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pandas \u001b[2m(9.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m rasterio \u001b[2m(28.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m scikit-learn \u001b[2m(7.6MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m matplotlib \u001b[2m(7.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m jedi \u001b[2m(1.5MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m babel \u001b[2m(9.7MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m notebook \u001b[2m(13.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m jupyterlab \u001b[2m(11.8MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m widgetsnbextension \u001b[2m(2.1MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m netcdf4 \u001b[2m(20.3MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m dask \u001b[2m(1.4MiB)\u001b[0m\n",
      "\u001b[36m\u001b[1mDownloading\u001b[0m\u001b[39m pydap \u001b[2m(2.3MiB)\u001b[0m\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m shapely\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m pywinpty\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m widgetsnbextension\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m xarray\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m pydap\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m pygments\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m dask\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m lxml\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m debugpy\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m matplotlib\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m scikit-learn\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m babel\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m jupyterlab\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m netcdf4\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m notebook\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m rasterio\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m pandas\n",
      " \u001b[36m\u001b[1mDownloaded\u001b[0m\u001b[39m jedi\n",
      "\u001b[2mPrepared \u001b[1m98 packages\u001b[0m \u001b[2min 2m 00s\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to install: arrow-1.4.0-py3-none-any.whl (arrow==1.4.0)\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to create directory `c:\\Program Files\\Python313\\Lib\\site-packages\\arrow`: AccÃ¨s refusÃ©. (os error 5)\n"
     ]
    }
   ],
   "source": [
    "!pip install uv\n",
    "!uv pip install --system -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38a3a2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting odc-stac\n",
      "  Downloading odc_stac-0.5.2-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting affine (from odc-stac)\n",
      "  Using cached affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting odc-geo>=0.4.7 (from odc-stac)\n",
      "  Downloading odc_geo-0.5.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting odc-loader>=0.6.4 (from odc-stac)\n",
      "  Downloading odc_loader-0.6.4-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting rasterio!=1.3.0,!=1.3.1,>=1.0.0 (from odc-stac)\n",
      "  Downloading rasterio-1.5.0-cp313-cp313-win_amd64.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: dask[array] in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (2026.1.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (2.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (2.3.0)\n",
      "Requirement already satisfied: pystac<2,>=1.0.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (1.14.3)\n",
      "Requirement already satisfied: toolz in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (1.1.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (4.14.0)\n",
      "Requirement already satisfied: xarray>=0.19 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-stac) (2026.1.0)\n",
      "Requirement already satisfied: cachetools in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from odc-geo>=0.4.7->odc-stac) (6.2.4)\n",
      "Collecting pyproj>=3.0.0 (from odc-geo>=0.4.7->odc-stac)\n",
      "  Downloading pyproj-3.7.2-cp313-cp313-win_amd64.whl.metadata (31 kB)\n",
      "Collecting shapely (from odc-geo>=0.4.7->odc-stac)\n",
      "  Downloading shapely-2.1.2-cp313-cp313-win_amd64.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from pystac<2,>=1.0.0->odc-stac) (2.9.0.post0)\n",
      "Requirement already satisfied: attrs in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac) (24.3.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac) (2024.12.14)\n",
      "Collecting click!=8.2.*,>=4.0 (from rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac)\n",
      "  Downloading click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting cligj>=0.5 (from rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac)\n",
      "  Using cached cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac) (3.2.3)\n",
      "Requirement already satisfied: packaging>=24.1 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from xarray>=0.19->odc-stac) (24.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from pandas->odc-stac) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from pandas->odc-stac) (2025.2)\n",
      "Requirement already satisfied: cloudpickle>=3.0.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from dask[array]->odc-stac) (3.1.1)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from dask[array]->odc-stac) (2025.5.1)\n",
      "Requirement already satisfied: partd>=1.4.0 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from dask[array]->odc-stac) (1.4.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from dask[array]->odc-stac) (6.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from click!=8.2.*,>=4.0->rasterio!=1.3.0,!=1.3.1,>=1.0.0->odc-stac) (0.4.6)\n",
      "Requirement already satisfied: locket in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from partd>=1.4.0->dask[array]->odc-stac) (1.0.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.7.0->pystac<2,>=1.0.0->odc-stac) (1.17.0)\n",
      "Downloading odc_stac-0.5.2-py3-none-any.whl (43 kB)\n",
      "Downloading odc_geo-0.5.0-py3-none-any.whl (159 kB)\n",
      "Downloading odc_loader-0.6.4-py3-none-any.whl (58 kB)\n",
      "Downloading rasterio-1.5.0-cp313-cp313-win_amd64.whl (30.1 MB)\n",
      "   ---------------------------------------- 0.0/30.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 4.7/30.1 MB 23.5 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 9.4/30.1 MB 22.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 14.7/30.1 MB 22.8 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 19.7/30.1 MB 22.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 25.2/30.1 MB 22.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  29.9/30.1 MB 22.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 30.1/30.1 MB 20.6 MB/s eta 0:00:00\n",
      "Using cached affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading pyproj-3.7.2-cp313-cp313-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 4.7/6.3 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 19.3 MB/s eta 0:00:00\n",
      "Downloading shapely-2.1.2-cp313-cp313-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.4 MB/s eta 0:00:00\n",
      "Installing collected packages: shapely, pyproj, click, affine, cligj, rasterio, odc-geo, odc-loader, odc-stac\n",
      "  Attempting uninstall: click\n",
      "    Found existing installation: click 8.2.1\n",
      "    Uninstalling click-8.2.1:\n",
      "      Successfully uninstalled click-8.2.1\n",
      "Successfully installed affine-2.4.0 click-8.3.1 cligj-0.7.2 odc-geo-0.5.0 odc-loader-0.6.4 odc-stac-0.5.2 pyproj-3.7.2 rasterio-1.5.0 shapely-2.1.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install odc-stac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imports",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "# Snowflake (uniquement si le notebook tourne dans Snowflake Notebooks)\n",
    "# Commenter ces lignes pour exÃ©cuter en local\n",
    "# import snowflake\n",
    "# from snowflake.snowpark.context import get_active_session\n",
    "# session = get_active_session()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Manipulation de donnÃ©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# AccÃ¨s Ã  l'API Microsoft Planetary Computer\n",
    "import pystac_client      # Pour naviguer dans le catalogue de donnÃ©es\n",
    "import planetary_computer as pc  # Pour s'authentifier\n",
    "from odc.stac import stac_load  # Pour charger les donnÃ©es satellite\n",
    "\n",
    "# Traitement parallÃ¨le (pour accÃ©lÃ©rer l'extraction)\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "from datetime import date\n",
    "from tqdm import tqdm  # Barre de progression\n",
    "import os\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-functions",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ã‰tape 2 : DÃ©finition des fonctions\n",
    "\n",
    "On va crÃ©er 3 fonctions :\n",
    "\n",
    "| Fonction | RÃ´le |\n",
    "|----------|------|\n",
    "| `extract_landsat_for_point()` | Extrait les valeurs Landsat pour un point donnÃ© |\n",
    "| `extract_landsat_batch()` | Traite un lot de points en parallÃ¨le |\n",
    "| `compute_spectral_indices()` | Calcule NDMI et MNDWI Ã  partir des bandes |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-landsat",
   "metadata": {},
   "source": [
    "### Comprendre les bandes Landsat\n",
    "\n",
    "Landsat capture la lumiÃ¨re Ã  diffÃ©rentes longueurs d'onde (bandes spectrales) :\n",
    "\n",
    "```\n",
    "Spectre Ã©lectromagnÃ©tique :\n",
    "\n",
    "    Visible                    Infrarouge\n",
    "    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "    â”‚  Blue  Green  Red  â”‚  NIR     SWIR16     SWIR22      â”‚\n",
    "    â”‚   ğŸ”µ    ğŸŸ¢    ğŸ”´   â”‚   ğŸŸ¤       â¬›         â¬›         â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "     0.4    0.5   0.6    0.8      1.6        2.2    (Î¼m)\n",
    "```\n",
    "\n",
    "**Bandes utilisÃ©es pour la qualitÃ© de l'eau :**\n",
    "\n",
    "| Bande | Nom | UtilitÃ© |\n",
    "|-------|-----|----------|\n",
    "| **green** | Vert (0.53-0.59 Î¼m) | PÃ©nÃ¨tre l'eau, dÃ©tecte turbiditÃ©/algues |\n",
    "| **nir08** | Proche infrarouge (0.85-0.88 Î¼m) | AbsorbÃ© par l'eau, dÃ©tecte vÃ©gÃ©tation |\n",
    "| **swir16** | SWIR 1 (1.57-1.65 Î¼m) | DÃ©tecte humiditÃ© du sol et vÃ©gÃ©tation |\n",
    "| **swir22** | SWIR 2 (2.11-2.29 Î¼m) | Distingue minÃ©raux et types de sol |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-buffer",
   "metadata": {},
   "source": [
    "### Pourquoi un buffer de 100 mÃ¨tres ?\n",
    "\n",
    "On ne prend pas juste le pixel exact du site de mesure, mais une zone de **100m autour** :\n",
    "\n",
    "```\n",
    "    Sans buffer (1 pixel)          Avec buffer 100m (zone 3x3)\n",
    "    â”Œâ”€â”€â”€â”€â”€â”                         â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”\n",
    "    â”‚  â€¢  â”‚  30m                    â”‚     â”‚     â”‚     â”‚\n",
    "    â””â”€â”€â”€â”€â”€â”˜                         â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤\n",
    "                                    â”‚     â”‚  â€¢  â”‚     â”‚\n",
    "                                    â”œâ”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¤\n",
    "                                    â”‚     â”‚     â”‚     â”‚\n",
    "                                    â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜\n",
    "                                           ~100m\n",
    "```\n",
    "\n",
    "**Avantages du buffer :**\n",
    "1. **RÃ©duit le bruit** : Un seul pixel peut Ãªtre affectÃ© par des erreurs\n",
    "2. **MÃ©diane plus robuste** : On prend la mÃ©diane des pixels, moins sensible aux outliers\n",
    "3. **Correspond Ã  la rÃ©alitÃ©** : L'eau mesurÃ©e n'est pas un point mais une zone\n",
    "\n",
    "**Calcul du buffer en degrÃ©s :**\n",
    "- 1 degrÃ© â‰ˆ 111 km Ã  l'Ã©quateur\n",
    "- 100m Ã· 111000m = **0.0009 degrÃ©s**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-process",
   "metadata": {},
   "source": [
    "### SchÃ©ma du processus d'extraction\n",
    "\n",
    "Pour chaque site de mesure, voici ce qui se passe :\n",
    "\n",
    "```\n",
    "Site de mesure                    Catalogue Planetary Computer\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚ Lat: -28.76        â”‚   RequÃªte  â”‚ ScÃ¨nes Landsat disponibles: â”‚\n",
    "â”‚ Lon: 17.73         â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ â€¢ 2011-01-05 (nuages: 45%) âŒâ”‚\n",
    "â”‚ Date: 02-01-2011   â”‚            â”‚ â€¢ 2011-01-15 (nuages: 5%)  âœ“â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚ â€¢ 2011-01-21 (nuages: 12%) âŒâ”‚\n",
    "                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                                              â”‚\n",
    "                                              â–¼\n",
    "                              SÃ©lection : scÃ¨ne la plus proche\n",
    "                              avec nuages < 10%\n",
    "                                              â”‚\n",
    "                                              â–¼\n",
    "                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "                              â”‚ Extraction des bandes :     â”‚\n",
    "                              â”‚ â€¢ green: 0.142 (mÃ©diane)    â”‚\n",
    "                              â”‚ â€¢ nir08: 0.231 (mÃ©diane)    â”‚\n",
    "                              â”‚ â€¢ swir16: 0.187 (mÃ©diane)   â”‚\n",
    "                              â”‚ â€¢ swir22: 0.098 (mÃ©diane)   â”‚\n",
    "                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "func-extract-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Buffer de ~100m autour de chaque point (en degrÃ©s)\n",
    "BUFFER_DEG = 0.0009\n",
    "\n",
    "# Bandes spectrales Ã  extraire\n",
    "BANDS = [\"green\", \"nir08\", \"swir16\", \"swir22\"]\n",
    "\n",
    "# PÃ©riode de recherche des donnÃ©es\n",
    "DATE_RANGE = \"2011-01-01/2015-12-31\"\n",
    "\n",
    "# Seuil de couverture nuageuse maximum (%)\n",
    "MAX_CLOUD_COVER = 10\n",
    "\n",
    "# Nombre de workers pour le traitement parallÃ¨le\n",
    "N_WORKERS = 4\n",
    "\n",
    "# Dossier de sortie\n",
    "OUTPUT_DIR = \"../data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "func-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog():\n",
    "    \"\"\"\n",
    "    Initialise la connexion au catalogue Planetary Computer.\n",
    "    \n",
    "    Retourne :\n",
    "        pystac_client.Client : Client connectÃ© au catalogue\n",
    "    \"\"\"\n",
    "    return pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=pc.sign_inplace,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "func-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landsat_for_point(lat, lon, sample_date, catalog=None):\n",
    "    \"\"\"\n",
    "    Extrait les valeurs Landsat pour un point gÃ©ographique donnÃ©.\n",
    "    \n",
    "    ParamÃ¨tres :\n",
    "        lat : float - Latitude du site\n",
    "        lon : float - Longitude du site\n",
    "        sample_date : str ou datetime - Date de l'Ã©chantillon\n",
    "        catalog : pystac_client.Client - Catalogue (optionnel, crÃ©Ã© si non fourni)\n",
    "    \n",
    "    Retourne :\n",
    "        dict : Valeurs mÃ©dianes pour chaque bande (ou NaN si Ã©chec)\n",
    "    \n",
    "    Processus :\n",
    "        1. CrÃ©er une bounding box de ~100m autour du point\n",
    "        2. Chercher les scÃ¨nes Landsat avec peu de nuages\n",
    "        3. SÃ©lectionner la scÃ¨ne la plus proche de la date\n",
    "        4. Extraire la mÃ©diane des pixels dans la bounding box\n",
    "    \"\"\"\n",
    "    \n",
    "    # RÃ©sultat par dÃ©faut en cas d'Ã©chec\n",
    "    default_result = {band: np.nan for band in BANDS}\n",
    "    \n",
    "    try:\n",
    "        # Convertir la date\n",
    "        if isinstance(sample_date, str):\n",
    "            sample_date = pd.to_datetime(sample_date, dayfirst=True, errors='coerce')\n",
    "        \n",
    "        if pd.isna(sample_date):\n",
    "            return default_result\n",
    "        \n",
    "        # CrÃ©er la bounding box (~100m autour du point)\n",
    "        bbox = [\n",
    "            lon - BUFFER_DEG / 2,  # min_lon\n",
    "            lat - BUFFER_DEG / 2,  # min_lat\n",
    "            lon + BUFFER_DEG / 2,  # max_lon\n",
    "            lat + BUFFER_DEG / 2   # max_lat\n",
    "        ]\n",
    "        \n",
    "        # Initialiser le catalogue si non fourni\n",
    "        if catalog is None:\n",
    "            catalog = get_catalog()\n",
    "        \n",
    "        # Rechercher les scÃ¨nes Landsat\n",
    "        search = catalog.search(\n",
    "            collections=[\"landsat-c2-l2\"],\n",
    "            bbox=bbox,\n",
    "            datetime=DATE_RANGE,\n",
    "            query={\"eo:cloud_cover\": {\"lt\": MAX_CLOUD_COVER}},\n",
    "        )\n",
    "        \n",
    "        items = search.item_collection()\n",
    "        \n",
    "        # Pas de scÃ¨ne disponible\n",
    "        if not items:\n",
    "            return default_result\n",
    "        \n",
    "        # Convertir la date en UTC pour comparaison\n",
    "        sample_date_utc = sample_date.tz_localize(\"UTC\") if sample_date.tzinfo is None else sample_date.tz_convert(\"UTC\")\n",
    "        \n",
    "        # Trier par proximitÃ© Ã  la date d'Ã©chantillonnage\n",
    "        items_sorted = sorted(\n",
    "            items,\n",
    "            key=lambda x: abs(pd.to_datetime(x.properties[\"datetime\"]).tz_convert(\"UTC\") - sample_date_utc)\n",
    "        )\n",
    "        \n",
    "        # SÃ©lectionner la scÃ¨ne la plus proche\n",
    "        selected_item = pc.sign(items_sorted[0])\n",
    "        \n",
    "        # Charger les bandes\n",
    "        data = stac_load([selected_item], bands=BANDS, bbox=bbox).isel(time=0)\n",
    "        \n",
    "        # Calculer les mÃ©dianes\n",
    "        result = {}\n",
    "        for band in BANDS:\n",
    "            median_val = float(data[band].astype(\"float\").median(skipna=True).values)\n",
    "            # Remplacer 0 par NaN (valeur invalide)\n",
    "            result[band] = median_val if median_val != 0 else np.nan\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        return default_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "func-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_landsat_batch(df, n_workers=N_WORKERS):\n",
    "    \"\"\"\n",
    "    Extrait les valeurs Landsat pour tous les points d'un DataFrame.\n",
    "    Utilise le traitement parallÃ¨le pour accÃ©lÃ©rer l'extraction.\n",
    "    \n",
    "    ParamÃ¨tres :\n",
    "        df : DataFrame - Doit contenir 'Latitude', 'Longitude', 'Sample Date'\n",
    "        n_workers : int - Nombre de threads parallÃ¨les\n",
    "    \n",
    "    Retourne :\n",
    "        DataFrame : Valeurs Landsat pour chaque point\n",
    "    \n",
    "    Note :\n",
    "        Le traitement parallÃ¨le accÃ©lÃ¨re significativement l'extraction\n",
    "        car les appels API sont I/O-bound (attente rÃ©seau).\n",
    "    \"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # PrÃ©parer les donnÃ©es\n",
    "    points = list(df[['Latitude', 'Longitude', 'Sample Date']].itertuples(index=False))\n",
    "    \n",
    "    # Traitement parallÃ¨le avec ThreadPoolExecutor\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        # Soumettre toutes les tÃ¢ches\n",
    "        future_to_idx = {\n",
    "            executor.submit(extract_landsat_for_point, lat, lon, date): idx\n",
    "            for idx, (lat, lon, date) in enumerate(points)\n",
    "        }\n",
    "        \n",
    "        # Initialiser les rÃ©sultats avec des NaN\n",
    "        results = [{band: np.nan for band in BANDS} for _ in range(len(points))]\n",
    "        \n",
    "        # Collecter les rÃ©sultats avec barre de progression\n",
    "        for future in tqdm(as_completed(future_to_idx), total=len(points), desc=\"Extraction Landsat\"):\n",
    "            idx = future_to_idx[future]\n",
    "            try:\n",
    "                results[idx] = future.result()\n",
    "            except Exception as e:\n",
    "                pass  # Garde les NaN par dÃ©faut\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "func-indices",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_spectral_indices(df):\n",
    "    \"\"\"\n",
    "    Calcule les indices spectraux Ã  partir des bandes Landsat.\n",
    "    \n",
    "    ParamÃ¨tres :\n",
    "        df : DataFrame - Doit contenir 'nir08', 'green', 'swir16'\n",
    "    \n",
    "    Retourne :\n",
    "        DataFrame : Avec colonnes NDMI et MNDWI ajoutÃ©es\n",
    "    \n",
    "    Indices calculÃ©s :\n",
    "        - NDMI : Normalized Difference Moisture Index\n",
    "        - MNDWI : Modified Normalized Difference Water Index\n",
    "    \"\"\"\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Epsilon pour Ã©viter la division par zÃ©ro\n",
    "    eps = 1e-10\n",
    "    \n",
    "    # NDMI = (NIR - SWIR16) / (NIR + SWIR16)\n",
    "    # Mesure le contenu en eau de la vÃ©gÃ©tation\n",
    "    df['NDMI'] = (df['nir08'] - df['swir16']) / (df['nir08'] + df['swir16'] + eps)\n",
    "    \n",
    "    # MNDWI = (Green - SWIR16) / (Green + SWIR16)\n",
    "    # DÃ©tecte les surfaces d'eau libre\n",
    "    df['MNDWI'] = (df['green'] - df['swir16']) / (df['green'] + df['swir16'] + eps)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-indices",
   "metadata": {},
   "source": [
    "### Indices spectraux calculÃ©s\n",
    "\n",
    "Ã€ partir des bandes brutes, on calcule deux indices utiles pour la qualitÃ© de l'eau :\n",
    "\n",
    "**NDMI (Normalized Difference Moisture Index)**\n",
    "```\n",
    "NDMI = (NIR - SWIR16) / (NIR + SWIR16)\n",
    "```\n",
    "- Mesure le **contenu en eau** de la vÃ©gÃ©tation et du sol\n",
    "- Valeurs hautes (0.4 Ã  1.0) â†’ zones humides, vÃ©gÃ©tation bien irriguÃ©e\n",
    "- Valeurs basses (-1.0 Ã  0.0) â†’ sol sec, stress hydrique\n",
    "\n",
    "**MNDWI (Modified Normalized Difference Water Index)**\n",
    "```\n",
    "MNDWI = (Green - SWIR16) / (Green + SWIR16)\n",
    "```\n",
    "- DÃ©tecte les **surfaces d'eau libre**\n",
    "- Valeurs positives â†’ prÃ©sence d'eau\n",
    "- Valeurs nÃ©gatives â†’ sol ou vÃ©gÃ©tation\n",
    "\n",
    "```\n",
    "InterprÃ©tation visuelle :\n",
    "\n",
    "NDMI :  -1.0 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º +1.0\n",
    "         ğŸœï¸ Sec                      Humide ğŸ’§\n",
    "\n",
    "MNDWI : -1.0 â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º +1.0\n",
    "         ğŸŒ¿ VÃ©gÃ©tation                  Eau ğŸŒŠ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-training",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ã‰tape 3 : Extraction pour les donnÃ©es d'entraÃ®nement\n",
    "\n",
    "### Variables Landsat extraites\n",
    "\n",
    "| Variable | Description | Lien avec la qualitÃ© de l'eau |\n",
    "|----------|-------------|-------------------------------|\n",
    "| **green** | Bande verte | PÃ©nÃ¨tre l'eau, dÃ©tecte turbiditÃ© |\n",
    "| **nir08** | Proche infrarouge | Distingue eau/vÃ©gÃ©tation |\n",
    "| **swir16** | Infrarouge ondes courtes 1 | HumiditÃ© du sol |\n",
    "| **swir22** | Infrarouge ondes courtes 2 | MinÃ©raux, types de sol |\n",
    "| **NDMI** | Indice d'humiditÃ© | Stress hydrique environnant |\n",
    "| **MNDWI** | Indice d'eau | PrÃ©sence/Ã©tendue de l'eau |\n",
    "\n",
    "âš ï¸ **Temps d'exÃ©cution** : L'extraction complÃ¨te (9319 points) peut prendre plusieurs heures. Pour tester, vous pouvez d'abord extraire un sous-ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "load-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sites : 9319\n",
      "Colonnes : ['Latitude', 'Longitude', 'Sample Date', 'Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>Total Alkalinity</th>\n",
       "      <th>Electrical Conductance</th>\n",
       "      <th>Dissolved Reactive Phosphorus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>128.912</td>\n",
       "      <td>555.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>74.720</td>\n",
       "      <td>162.9</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>89.254</td>\n",
       "      <td>573.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>82.000</td>\n",
       "      <td>203.6</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>56.100</td>\n",
       "      <td>145.1</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date  Total Alkalinity  Electrical Conductance  \\\n",
       "0 -28.760833  17.730278  02-01-2011           128.912                   555.0   \n",
       "1 -26.861111  28.884722  03-01-2011            74.720                   162.9   \n",
       "2 -26.450000  28.085833  03-01-2011            89.254                   573.0   \n",
       "3 -27.671111  27.236944  03-01-2011            82.000                   203.6   \n",
       "4 -27.356667  27.286389  03-01-2011            56.100                   145.1   \n",
       "\n",
       "   Dissolved Reactive Phosphorus  \n",
       "0                           10.0  \n",
       "1                          163.0  \n",
       "2                           80.0  \n",
       "3                          101.0  \n",
       "4                          151.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Charger les donnÃ©es de qualitÃ© d'eau (nos sites de mesure)\n",
    "Water_Quality_df = pd.read_csv(\"../data/raw/water_quality_training_dataset.csv\")\n",
    "\n",
    "print(f\"Nombre de sites : {len(Water_Quality_df)}\")\n",
    "print(f\"Colonnes : {list(Water_Quality_df.columns)}\")\n",
    "display(Water_Quality_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extract-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction pour 200 points...\n",
      "Nombre de workers parallÃ¨les : 4\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction Landsat: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [04:31<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTION TERMINÃ‰E !\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION DES DONNÃ‰ES LANDSAT - TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "# Option 1 : Extraire tous les points (LONG - plusieurs heures)\n",
    "# df_to_process = Water_Quality_df\n",
    "\n",
    "# Option 2 : Extraire un sous-ensemble pour tester (RAPIDE - quelques minutes)\n",
    "df_to_process = Water_Quality_df.head(200)  # Modifier ce nombre selon vos besoins\n",
    "\n",
    "print(f\"Extraction pour {len(df_to_process)} points...\")\n",
    "print(f\"Nombre de workers parallÃ¨les : {N_WORKERS}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extraire les valeurs Landsat\n",
    "landsat_features = extract_landsat_batch(df_to_process, n_workers=N_WORKERS)\n",
    "\n",
    "# Calculer les indices spectraux\n",
    "landsat_features = compute_spectral_indices(landsat_features)\n",
    "\n",
    "# Renommer les colonnes pour cohÃ©rence\n",
    "landsat_features = landsat_features.rename(columns={'nir08': 'nir'})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION TERMINÃ‰E !\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae027a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "landsat_features.to_csv(\"landsat_features_200_premieres_lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-training-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRÃ‰ER LE FICHIER CSV FINAL - TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "# Ajouter les coordonnÃ©es et dates\n",
    "landsat_train_df = pd.DataFrame({\n",
    "    'Latitude': df_to_process['Latitude'].values,\n",
    "    'Longitude': df_to_process['Longitude'].values,\n",
    "    'Sample Date': df_to_process['Sample Date'].values,\n",
    "})\n",
    "\n",
    "# Ajouter les features Landsat\n",
    "for col in ['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']:\n",
    "    landsat_train_df[col] = landsat_features[col].values\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'landsat_features_training.csv')\n",
    "landsat_train_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier crÃ©Ã© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-training",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AperÃ§u du fichier crÃ©Ã©\n",
    "print(\"AperÃ§u des donnÃ©es extraites :\")\n",
    "print(f\"- Lignes : {len(landsat_train_df)}\")\n",
    "print(f\"- Colonnes : {list(landsat_train_df.columns)}\")\n",
    "print(f\"\\nStatistiques des features Landsat :\")\n",
    "print(landsat_train_df[['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']].describe().round(4))\n",
    "print(f\"\\nValeurs manquantes :\")\n",
    "print(landsat_train_df.isna().sum())\n",
    "display(landsat_train_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-training-snowflake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder dans /tmp et uploader vers Snowflake (uniquement si le notebook tourne dans Snowflake)\n",
    "# DÃ©commenter ces lignes pour exÃ©cuter dans Snowflake\n",
    "\n",
    "# landsat_train_df.to_csv(\"/tmp/landsat_features_training.csv\", index=False)\n",
    "# session.sql(f\"\"\"\n",
    "#     PUT file:///tmp/landsat_features_training.csv\n",
    "#     snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n",
    "#     AUTO_COMPRESS=FALSE\n",
    "#     OVERWRITE=TRUE\n",
    "# \"\"\").collect()\n",
    "# print(\"Fichier uploadÃ© vers Snowflake !\")\n",
    "\n",
    "print(\"Fichier 'landsat_features_training.csv' sauvegardÃ© localement !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-validation",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Ã‰tape 4 : Extraction pour les donnÃ©es de validation (test)\n",
    "\n",
    "MÃªme processus, mais pour les donnÃ©es de **validation** (le fichier `submission_template.csv`).\n",
    "\n",
    "C'est ce fichier qu'on utilisera pour faire nos prÃ©dictions finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le template de soumission (sites de validation)\n",
    "Validation_df = pd.read_csv('../data/raw/submission_template.csv')\n",
    "\n",
    "print(f\"Nombre de sites de validation : {len(Validation_df)}\")\n",
    "display(Validation_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION DES DONNÃ‰ES LANDSAT - VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Extraction pour {len(Validation_df)} points de validation...\")\n",
    "print(f\"Nombre de workers parallÃ¨les : {N_WORKERS}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Extraire les valeurs Landsat\n",
    "landsat_val_features = extract_landsat_batch(Validation_df, n_workers=N_WORKERS)\n",
    "\n",
    "# Calculer les indices spectraux\n",
    "landsat_val_features = compute_spectral_indices(landsat_val_features)\n",
    "\n",
    "# Renommer les colonnes pour cohÃ©rence\n",
    "landsat_val_features = landsat_val_features.rename(columns={'nir08': 'nir'})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION VALIDATION TERMINÃ‰E !\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "create-validation-df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CRÃ‰ER LE FICHIER CSV FINAL - VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "# Ajouter les coordonnÃ©es et dates\n",
    "landsat_val_df = pd.DataFrame({\n",
    "    'Latitude': Validation_df['Latitude'].values,\n",
    "    'Longitude': Validation_df['Longitude'].values,\n",
    "    'Sample Date': Validation_df['Sample Date'].values,\n",
    "})\n",
    "\n",
    "# Ajouter les features Landsat\n",
    "for col in ['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']:\n",
    "    landsat_val_df[col] = landsat_val_features[col].values\n",
    "\n",
    "# Sauvegarder en CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'landsat_features_validation.csv')\n",
    "landsat_val_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier crÃ©Ã© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preview-validation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AperÃ§u des donnÃ©es de validation\n",
    "print(f\"DonnÃ©es de validation : {len(landsat_val_df)} lignes\")\n",
    "print(f\"Colonnes : {list(landsat_val_df.columns)}\")\n",
    "print(f\"\\nStatistiques des features Landsat :\")\n",
    "print(landsat_val_df[['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI']].describe().round(4))\n",
    "print(f\"\\nValeurs manquantes :\")\n",
    "print(landsat_val_df.isna().sum())\n",
    "display(landsat_val_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upload-validation-snowflake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder dans /tmp et uploader vers Snowflake (uniquement si le notebook tourne dans Snowflake)\n",
    "# DÃ©commenter ces lignes pour exÃ©cuter dans Snowflake\n",
    "\n",
    "# landsat_val_df.to_csv(\"/tmp/landsat_features_validation.csv\", index=False)\n",
    "# session.sql(f\"\"\"\n",
    "#     PUT file:///tmp/landsat_features_validation.csv\n",
    "#     snow://workspace/USER$.PUBLIC.DEFAULT$/versions/live/\n",
    "#     AUTO_COMPRESS=FALSE\n",
    "#     OVERWRITE=TRUE\n",
    "# \"\"\").collect()\n",
    "# print(\"Fichier uploadÃ© vers Snowflake !\")\n",
    "\n",
    "print(\"Fichier 'landsat_features_validation.csv' sauvegardÃ© localement !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## RÃ©sumÃ©\n",
    "\n",
    "**Ce qu'on a fait :**\n",
    "1. ConnectÃ© Ã  Microsoft Planetary Computer\n",
    "2. Pour chaque site de mesure :\n",
    "   - TrouvÃ© l'image Landsat la plus proche (nuages < 10%)\n",
    "   - Extrait les valeurs spectrales (buffer 100m, mÃ©diane)\n",
    "3. CalculÃ© les indices spectraux (NDMI, MNDWI)\n",
    "4. CrÃ©Ã© 2 fichiers CSV avec toutes les features\n",
    "\n",
    "**Variables extraites :**\n",
    "\n",
    "| Variable | Description |\n",
    "|----------|-------------|\n",
    "| nir | Proche infrarouge (bande 5) |\n",
    "| green | Vert (bande 3) |\n",
    "| swir16 | Infrarouge ondes courtes 1 (bande 6) |\n",
    "| swir22 | Infrarouge ondes courtes 2 (bande 7) |\n",
    "| NDMI | Normalized Difference Moisture Index |\n",
    "| MNDWI | Modified Normalized Difference Water Index |\n",
    "\n",
    "**Fichiers crÃ©Ã©s :**\n",
    "\n",
    "| Fichier | Lignes | Colonnes |\n",
    "|---------|--------|----------|\n",
    "| landsat_features_training.csv | ~9300 | Latitude, Longitude, Sample Date + 6 variables |\n",
    "| landsat_features_validation.csv | 200 | Latitude, Longitude, Sample Date + 6 variables |\n",
    "\n",
    "**Note sur les valeurs manquantes :**\n",
    "\n",
    "Certains points peuvent avoir des valeurs NaN si :\n",
    "- Aucune image Landsat n'est disponible pour cette date/localisation\n",
    "- Toutes les images disponibles ont trop de nuages (>10%)\n",
    "- Le pixel est invalide (erreur de capteur)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
