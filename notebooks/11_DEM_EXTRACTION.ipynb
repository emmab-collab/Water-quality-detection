{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# DEM - Extraction des Donn√©es Topographiques\n",
    "\n",
    "## C'est quoi un DEM ?\n",
    "\n",
    "**DEM (Digital Elevation Model)** est un mod√®le num√©rique de terrain :\n",
    "- Repr√©sente l'altitude de chaque point de la surface terrestre\n",
    "- Permet de calculer la pente et l'orientation\n",
    "\n",
    "## Pourquoi c'est utile pour la qualit√© de l'eau ?\n",
    "\n",
    "La topographie influence fortement l'hydrologie :\n",
    "\n",
    "| Variable | Impact sur la qualit√© de l'eau |\n",
    "|----------|--------------------------------|\n",
    "| **Altitude** | Temp√©rature, pr√©cipitations, type de v√©g√©tation |\n",
    "| **Pente** | Vitesse d'√©coulement, √©rosion, temps de r√©sidence |\n",
    "| **Orientation** | Ensoleillement, √©vaporation |\n",
    "\n",
    "## Variables extraites\n",
    "\n",
    "| Variable | Unit√© | Description |\n",
    "|----------|-------|-------------|\n",
    "| `elevation` | m√®tres | Altitude du point |\n",
    "| `slope` | degr√©s | Pente locale (0-90¬∞) |\n",
    "| `aspect` | degr√©s | Orientation (0-360¬∞, Nord=0) |\n",
    "\n",
    "## Source des donn√©es\n",
    "\n",
    "**Copernicus DEM GLO-30** sur Planetary Computer\n",
    "- R√©solution : 30 m√®tres\n",
    "- Couverture : mondiale\n",
    "- Documentation : [Copernicus DEM](https://planetarycomputer.microsoft.com/dataset/cop-dem-glo-30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 1 : Installation des d√©pendances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: uv in c:\\users\\manu\\appdata\\roaming\\python\\python313\\site-packages (0.9.18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\u001b[2mUsing Python 3.13.1 environment at: c:\\Program Files\\Python313\u001b[0m\n",
      "\u001b[2mResolved \u001b[1m194 packages\u001b[0m \u001b[2min 632ms\u001b[0m\u001b[0m\n",
      "\u001b[1m\u001b[31merror\u001b[39m\u001b[0m: Failed to install: jupyter_events-0.12.0-py3-none-any.whl (jupyter-events==0.12.0)\n",
      "  \u001b[1m\u001b[31mCaused by\u001b[39m\u001b[0m: failed to create directory `c:\\Program Files\\Python313\\Lib\\site-packages\\jupyter_events`: Acc√®s refus√©. (os error 5)\n"
     ]
    }
   ],
   "source": [
    "!pip install uv\n",
    "!uv pip install --system -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports OK!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Manipulation de donn√©es\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manipulation d'images raster\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform_bounds\n",
    "\n",
    "# Acc√®s √† l'API Microsoft Planetary Computer\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constants-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 2 : D√©finition des constantes et fonctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "constants-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection DEM : cop-dem-glo-30\n",
      "Buffer : ~555m\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CONSTANTES\n",
    "# =============================================================================\n",
    "\n",
    "# Collection Copernicus DEM sur Planetary Computer\n",
    "DEM_COLLECTION = \"cop-dem-glo-30\"\n",
    "\n",
    "# Taille du buffer en degr√©s (~500m)\n",
    "BUFFER_DEG = 0.005\n",
    "\n",
    "# Dossier de sortie\n",
    "OUTPUT_DIR = \"../data/processed\"\n",
    "\n",
    "print(f\"Collection DEM : {DEM_COLLECTION}\")\n",
    "print(f\"Buffer : ~{BUFFER_DEG * 111000:.0f}m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "catalog-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_catalog():\n",
    "    \"\"\"\n",
    "    Se connecte au catalogue Microsoft Planetary Computer.\n",
    "    \"\"\"\n",
    "    catalog = pystac_client.Client.open(\n",
    "        \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "        modifier=pc.sign_inplace,\n",
    "    )\n",
    "    print(\"Connexion au catalogue Planetary Computer OK!\")\n",
    "    return catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functions-md",
   "metadata": {},
   "source": [
    "### Fonctions de calcul de pente et orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "slope-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(elevation_array, cell_size=30):\n",
    "    \"\"\"\n",
    "    Calcule la pente √† partir d'un array d'√©l√©vation.\n",
    "    \n",
    "    Param√®tres:\n",
    "        elevation_array : array 2D d'√©l√©vation\n",
    "        cell_size : taille du pixel en m√®tres\n",
    "    \n",
    "    Retourne:\n",
    "        pente moyenne en degr√©s\n",
    "    \"\"\"\n",
    "    if elevation_array.size < 9:  # Minimum 3x3\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculer les gradients\n",
    "    dy, dx = np.gradient(elevation_array, cell_size)\n",
    "    \n",
    "    # Pente = arctan(sqrt(dx¬≤ + dy¬≤))\n",
    "    slope_rad = np.arctan(np.sqrt(dx**2 + dy**2))\n",
    "    slope_deg = np.degrees(slope_rad)\n",
    "    \n",
    "    return float(np.nanmean(slope_deg))\n",
    "\n",
    "\n",
    "def calculate_aspect(elevation_array, cell_size=30):\n",
    "    \"\"\"\n",
    "    Calcule l'orientation (aspect) √† partir d'un array d'√©l√©vation.\n",
    "    \n",
    "    Param√®tres:\n",
    "        elevation_array : array 2D d'√©l√©vation\n",
    "        cell_size : taille du pixel en m√®tres\n",
    "    \n",
    "    Retourne:\n",
    "        orientation moyenne en degr√©s (0-360, Nord=0)\n",
    "    \"\"\"\n",
    "    if elevation_array.size < 9:\n",
    "        return np.nan\n",
    "    \n",
    "    # Calculer les gradients\n",
    "    dy, dx = np.gradient(elevation_array, cell_size)\n",
    "    \n",
    "    # Aspect = arctan2(-dx, dy) converti en degr√©s\n",
    "    aspect_rad = np.arctan2(-dx, dy)\n",
    "    aspect_deg = np.degrees(aspect_rad)\n",
    "    \n",
    "    # Convertir de [-180, 180] √† [0, 360]\n",
    "    aspect_deg = (aspect_deg + 360) % 360\n",
    "    \n",
    "    # Moyenne circulaire pour l'orientation\n",
    "    sin_mean = np.nanmean(np.sin(np.radians(aspect_deg)))\n",
    "    cos_mean = np.nanmean(np.cos(np.radians(aspect_deg)))\n",
    "    mean_aspect = np.degrees(np.arctan2(sin_mean, cos_mean))\n",
    "    mean_aspect = (mean_aspect + 360) % 360\n",
    "    \n",
    "    return float(mean_aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extract-md",
   "metadata": {},
   "source": [
    "### Fonction principale d'extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extract-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_dem_features(catalog, lat, lon, buffer_deg=0.005, debug=False):\n",
    "    \"\"\"\n",
    "    Extrait les features topographiques pour un point.\n",
    "    \n",
    "    Param√®tres:\n",
    "        catalog : catalogue Planetary Computer\n",
    "        lat, lon : coordonn√©es du point\n",
    "        buffer_deg : buffer en degr√©s autour du point\n",
    "        debug : afficher les messages de d√©bogage\n",
    "    \n",
    "    Retourne:\n",
    "        dict avec elevation, slope, aspect\n",
    "    \"\"\"\n",
    "    results = {\n",
    "        'elevation': np.nan,\n",
    "        'slope': np.nan,\n",
    "        'aspect': np.nan\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Bounding box\n",
    "        bbox = [\n",
    "            lon - buffer_deg,\n",
    "            lat - buffer_deg,\n",
    "            lon + buffer_deg,\n",
    "            lat + buffer_deg\n",
    "        ]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Bbox: {bbox}\")\n",
    "        \n",
    "        # Rechercher les tuiles DEM\n",
    "        search = catalog.search(\n",
    "            collections=[DEM_COLLECTION],\n",
    "            bbox=bbox,\n",
    "        )\n",
    "        items = list(search.items())\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Items trouv√©s: {len(items)}\")\n",
    "        \n",
    "        if len(items) == 0:\n",
    "            if debug:\n",
    "                print(\"  ‚ö†Ô∏è Pas de donn√©es\")\n",
    "            return results\n",
    "        \n",
    "        item = items[0]\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  Item: {item.id}\")\n",
    "            print(f\"  Assets: {list(item.assets.keys())}\")\n",
    "        \n",
    "        # Signer l'asset\n",
    "        signed_asset = pc.sign(item.assets[\"data\"])\n",
    "        \n",
    "        # Ouvrir et lire les donn√©es\n",
    "        with rasterio.open(signed_asset.href) as src:\n",
    "            # Transformer la bbox\n",
    "            dst_crs = src.crs\n",
    "            transformed_bbox = transform_bounds(\n",
    "                CRS.from_epsg(4326),\n",
    "                dst_crs,\n",
    "                *bbox\n",
    "            )\n",
    "            \n",
    "            window = from_bounds(*transformed_bbox, src.transform)\n",
    "            elevation_data = src.read(1, window=window)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Shape: {elevation_data.shape}\")\n",
    "                print(f\"  Elevation: min={elevation_data.min():.0f}, max={elevation_data.max():.0f}\")\n",
    "            \n",
    "            if elevation_data.size == 0:\n",
    "                return results\n",
    "            \n",
    "            # Filtrer les valeurs NoData\n",
    "            valid_data = elevation_data[elevation_data > -1000]\n",
    "            \n",
    "            if valid_data.size == 0:\n",
    "                return results\n",
    "            \n",
    "            # Calculer les features\n",
    "            results['elevation'] = float(np.mean(valid_data))\n",
    "            results['slope'] = calculate_slope(elevation_data, cell_size=30)\n",
    "            results['aspect'] = calculate_aspect(elevation_data, cell_size=30)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  Elevation: {results['elevation']:.1f}m\")\n",
    "                print(f\"  Slope: {results['slope']:.1f}¬∞\")\n",
    "                print(f\"  Aspect: {results['aspect']:.1f}¬∞\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        if debug:\n",
    "            print(f\"  ‚ùå Erreur: {type(e).__name__}: {e}\")\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "test-md",
   "metadata": {},
   "source": [
    "### Test de diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "test-cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test de diagnostic DEM (Copernicus)\n",
      "==================================================\n",
      "Connexion au catalogue Planetary Computer OK!\n",
      "\n",
      "Test avec le point: lat=-26.45, lon=28.085833\n",
      "--------------------------------------------------\n",
      "  Bbox: [28.080833000000002, -26.455, 28.090833, -26.445]\n",
      "  Items trouv√©s: 1\n",
      "  Item: Copernicus_DSM_COG_10_S27_00_E028_00_DEM\n",
      "  Assets: ['data', 'tilejson', 'rendered_preview']\n",
      "  Shape: (36, 36)\n",
      "  Elevation: min=1467, max=1485\n",
      "  Elevation: 1473.7m\n",
      "  Slope: 1.4¬∞\n",
      "  Aspect: 134.6¬∞\n",
      "\n",
      "==================================================\n",
      "R√©sultats:\n",
      "  elevation: 1473.7\n",
      "  slope: 1.4\n",
      "  aspect: 134.6\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# TEST DE DIAGNOSTIC\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Test de diagnostic DEM (Copernicus)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "catalog = get_catalog()\n",
    "\n",
    "# Point de test en Afrique du Sud\n",
    "test_lat, test_lon = -26.45, 28.085833\n",
    "\n",
    "print(f\"\\nTest avec le point: lat={test_lat}, lon={test_lon}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = extract_dem_features(catalog, test_lat, test_lon, debug=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"R√©sultats:\")\n",
    "for k, v in result.items():\n",
    "    if pd.notna(v):\n",
    "        print(f\"  {k}: {v:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 3 : Extraction pour les donn√©es d'entra√Ænement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "load-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'observations : 9319\n",
      "Sites uniques √† traiter : 162\n"
     ]
    }
   ],
   "source": [
    "# Charger les donn√©es\n",
    "Water_Quality_df = pd.read_csv(\"../data/raw/water_quality_training_dataset.csv\")\n",
    "\n",
    "print(f\"Nombre d'observations : {len(Water_Quality_df)}\")\n",
    "\n",
    "# Sites uniques\n",
    "training_sites = Water_Quality_df[['Latitude', 'Longitude']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Sites uniques √† traiter : {len(training_sites)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extract-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connexion √† Microsoft Planetary Computer...\n",
      "Connexion au catalogue Planetary Computer OK!\n",
      "\n",
      "Extraction pour 162 sites uniques...\n",
      "Sauvegarde automatique tous les 100 sites\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 100/162 [00:59<00:29,  2.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ Sauvegarde : 100/162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 162/162 [01:29<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction termin√©e : 162 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION DEM - TRAINING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Connexion √† Microsoft Planetary Computer...\")\n",
    "catalog = get_catalog()\n",
    "\n",
    "print(f\"\\nExtraction pour {len(training_sites)} sites uniques...\")\n",
    "\n",
    "# Fichier de sauvegarde incr√©mentale\n",
    "BACKUP_PATH = \"../data/processed/dem_training_backup.csv\"\n",
    "SAVE_EVERY = 100\n",
    "\n",
    "print(f\"Sauvegarde automatique tous les {SAVE_EVERY} sites\\n\")\n",
    "\n",
    "training_results = []\n",
    "completed_count = 0\n",
    "\n",
    "for idx, row in tqdm(training_sites.iterrows(), total=len(training_sites), desc=\"Extraction\"):\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    \n",
    "    # Extraire les features DEM\n",
    "    dem_features = extract_dem_features(catalog, lat, lon, BUFFER_DEG, debug=False)\n",
    "    \n",
    "    # Ajouter les coordonn√©es\n",
    "    result = {'Latitude': lat, 'Longitude': lon}\n",
    "    result.update(dem_features)\n",
    "    \n",
    "    training_results.append(result)\n",
    "    completed_count += 1\n",
    "    \n",
    "    # Sauvegarde incr√©mentale\n",
    "    if completed_count % SAVE_EVERY == 0:\n",
    "        backup_df = pd.DataFrame(training_results)\n",
    "        backup_df.to_csv(BACKUP_PATH, index=False)\n",
    "        print(f\"\\nüíæ Sauvegarde : {completed_count}/{len(training_sites)} sites\")\n",
    "\n",
    "# Sauvegarde finale\n",
    "training_dem_unique = pd.DataFrame(training_results)\n",
    "training_dem_unique.to_csv(BACKUP_PATH, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction termin√©e : {len(training_dem_unique)} sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "merge-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final : 9319 lignes\n"
     ]
    }
   ],
   "source": [
    "# Fusionner avec le DataFrame original\n",
    "training_dem_df = Water_Quality_df[['Latitude', 'Longitude', 'Sample Date']].merge(\n",
    "    training_dem_unique,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"DataFrame final : {len(training_dem_df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "save-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√© : ../data/processed\\dem_features_training.csv\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le fichier CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'dem_features_training.csv')\n",
    "training_dem_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier cr√©√© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stats-training",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aper√ßu des donn√©es extraites :\n",
      "- Lignes : 9319\n",
      "- Colonnes : ['Latitude', 'Longitude', 'Sample Date', 'elevation', 'slope', 'aspect']\n",
      "\n",
      "Statistiques des features topographiques :\n",
      "         elevation        slope       aspect\n",
      "count  9319.000000  9319.000000  9319.000000\n",
      "mean    924.211947     5.251166   178.098969\n",
      "std     509.823945     4.366169   103.745307\n",
      "min       5.359703     0.972492     0.081085\n",
      "25%     429.259399     2.323860    90.644226\n",
      "50%    1084.152832     3.458956   183.557205\n",
      "75%    1325.551270     6.884036   264.508942\n",
      "max    1620.325195    26.051317   359.604919\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-28.760833</td>\n",
       "      <td>17.730278</td>\n",
       "      <td>02-01-2011</td>\n",
       "      <td>192.663025</td>\n",
       "      <td>11.798665</td>\n",
       "      <td>299.497650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26.861111</td>\n",
       "      <td>28.884722</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1527.916626</td>\n",
       "      <td>2.923243</td>\n",
       "      <td>109.644104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-26.450000</td>\n",
       "      <td>28.085833</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1473.671143</td>\n",
       "      <td>1.366939</td>\n",
       "      <td>134.574402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-27.671111</td>\n",
       "      <td>27.236944</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1347.080688</td>\n",
       "      <td>3.807301</td>\n",
       "      <td>310.537842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-27.356667</td>\n",
       "      <td>27.286389</td>\n",
       "      <td>03-01-2011</td>\n",
       "      <td>1357.651001</td>\n",
       "      <td>1.690194</td>\n",
       "      <td>224.774612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date    elevation      slope      aspect\n",
       "0 -28.760833  17.730278  02-01-2011   192.663025  11.798665  299.497650\n",
       "1 -26.861111  28.884722  03-01-2011  1527.916626   2.923243  109.644104\n",
       "2 -26.450000  28.085833  03-01-2011  1473.671143   1.366939  134.574402\n",
       "3 -27.671111  27.236944  03-01-2011  1347.080688   3.807301  310.537842\n",
       "4 -27.356667  27.286389  03-01-2011  1357.651001   1.690194  224.774612"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aper√ßu des donn√©es extraites\n",
    "print(\"Aper√ßu des donn√©es extraites :\")\n",
    "print(f\"- Lignes : {len(training_dem_df)}\")\n",
    "print(f\"- Colonnes : {list(training_dem_df.columns)}\")\n",
    "\n",
    "# Statistiques\n",
    "dem_cols = ['elevation', 'slope', 'aspect']\n",
    "print(f\"\\nStatistiques des features topographiques :\")\n",
    "print(training_dem_df[dem_cols].describe())\n",
    "\n",
    "display(training_dem_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âtape 4 : Extraction pour les donn√©es de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "load-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de sites de validation : 200\n",
      "Sites uniques √† traiter : 24\n"
     ]
    }
   ],
   "source": [
    "# Charger le template de soumission\n",
    "Validation_df = pd.read_csv('../data/raw/submission_template.csv')\n",
    "\n",
    "print(f\"Nombre de sites de validation : {len(Validation_df)}\")\n",
    "\n",
    "# Sites uniques\n",
    "validation_sites = Validation_df[['Latitude', 'Longitude']].drop_duplicates().reset_index(drop=True)\n",
    "print(f\"Sites uniques √† traiter : {len(validation_sites)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "extract-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction pour 24 sites uniques...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extraction: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 24/24 [00:12<00:00,  1.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Extraction termin√©e : 24 sites\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# EXTRACTION DEM - VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Extraction pour {len(validation_sites)} sites uniques...\")\n",
    "\n",
    "BACKUP_PATH_VAL = \"../data/processed/dem_validation_backup.csv\"\n",
    "SAVE_EVERY_VAL = 50\n",
    "\n",
    "validation_results = []\n",
    "completed_count = 0\n",
    "\n",
    "for idx, row in tqdm(validation_sites.iterrows(), total=len(validation_sites), desc=\"Extraction\"):\n",
    "    lat, lon = row['Latitude'], row['Longitude']\n",
    "    \n",
    "    dem_features = extract_dem_features(catalog, lat, lon, BUFFER_DEG, debug=False)\n",
    "    \n",
    "    result = {'Latitude': lat, 'Longitude': lon}\n",
    "    result.update(dem_features)\n",
    "    \n",
    "    validation_results.append(result)\n",
    "    completed_count += 1\n",
    "    \n",
    "    if completed_count % SAVE_EVERY_VAL == 0:\n",
    "        backup_df = pd.DataFrame(validation_results)\n",
    "        backup_df.to_csv(BACKUP_PATH_VAL, index=False)\n",
    "        print(f\"\\nüíæ Sauvegarde : {completed_count}/{len(validation_sites)} sites\")\n",
    "\n",
    "# Sauvegarde finale\n",
    "validation_dem_unique = pd.DataFrame(validation_results)\n",
    "validation_dem_unique.to_csv(BACKUP_PATH_VAL, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Extraction termin√©e : {len(validation_dem_unique)} sites\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "merge-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame final : 200 lignes\n"
     ]
    }
   ],
   "source": [
    "# Fusionner avec le DataFrame original\n",
    "validation_dem_df = Validation_df[['Latitude', 'Longitude', 'Sample Date']].merge(\n",
    "    validation_dem_unique,\n",
    "    on=['Latitude', 'Longitude'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(f\"DataFrame final : {len(validation_dem_df)} lignes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "save-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier cr√©√© : ../data/processed\\dem_features_validation.csv\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder le fichier CSV\n",
    "output_path = os.path.join(OUTPUT_DIR, 'dem_features_validation.csv')\n",
    "validation_dem_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier cr√©√© : {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "stats-validation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Donn√©es de validation : 200 lignes\n",
      "\n",
      "Statistiques :\n",
      "        elevation       slope      aspect\n",
      "count  200.000000  200.000000  200.000000\n",
      "mean   419.181021   10.924888  185.274252\n",
      "std    319.368110    7.894237  110.095558\n",
      "min     42.320709    1.390205   21.941162\n",
      "25%    193.071960    3.837967   80.797882\n",
      "50%    248.035019   10.501728  195.292770\n",
      "75%    800.228394   12.302191  244.790375\n",
      "max    986.560364   30.558901  356.730499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Sample Date</th>\n",
       "      <th>elevation</th>\n",
       "      <th>slope</th>\n",
       "      <th>aspect</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-32.043333</td>\n",
       "      <td>27.822778</td>\n",
       "      <td>01-09-2014</td>\n",
       "      <td>800.228394</td>\n",
       "      <td>7.941890</td>\n",
       "      <td>244.790375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-33.329167</td>\n",
       "      <td>26.077500</td>\n",
       "      <td>16-09-2015</td>\n",
       "      <td>355.946747</td>\n",
       "      <td>21.501944</td>\n",
       "      <td>339.971893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-32.991639</td>\n",
       "      <td>27.640028</td>\n",
       "      <td>07-05-2015</td>\n",
       "      <td>193.071960</td>\n",
       "      <td>10.501728</td>\n",
       "      <td>356.730499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-34.096389</td>\n",
       "      <td>24.439167</td>\n",
       "      <td>07-02-2012</td>\n",
       "      <td>76.233414</td>\n",
       "      <td>12.302191</td>\n",
       "      <td>216.089355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-32.000556</td>\n",
       "      <td>28.581667</td>\n",
       "      <td>01-10-2014</td>\n",
       "      <td>437.481720</td>\n",
       "      <td>24.601475</td>\n",
       "      <td>21.941162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Latitude  Longitude Sample Date   elevation      slope      aspect\n",
       "0 -32.043333  27.822778  01-09-2014  800.228394   7.941890  244.790375\n",
       "1 -33.329167  26.077500  16-09-2015  355.946747  21.501944  339.971893\n",
       "2 -32.991639  27.640028  07-05-2015  193.071960  10.501728  356.730499\n",
       "3 -34.096389  24.439167  07-02-2012   76.233414  12.302191  216.089355\n",
       "4 -32.000556  28.581667  01-10-2014  437.481720  24.601475   21.941162"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aper√ßu des donn√©es de validation\n",
    "print(f\"Donn√©es de validation : {len(validation_dem_df)} lignes\")\n",
    "print(f\"\\nStatistiques :\")\n",
    "print(validation_dem_df[dem_cols].describe())\n",
    "\n",
    "display(validation_dem_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R√©sum√©\n",
    "\n",
    "**Ce qu'on a fait :**\n",
    "1. Connect√© √† Microsoft Planetary Computer (Copernicus DEM GLO-30)\n",
    "2. Pour chaque site de mesure, extrait :\n",
    "   - Altitude moyenne\n",
    "   - Pente moyenne\n",
    "   - Orientation moyenne\n",
    "3. Cr√©√© 2 fichiers CSV avec les features topographiques\n",
    "\n",
    "**Features extraites :**\n",
    "\n",
    "| Feature | Description | Impact attendu |\n",
    "|---------|-------------|----------------|\n",
    "| elevation | Altitude (m) | Temp√©rature, type d'√©cosyst√®me |\n",
    "| slope | Pente (¬∞) | Vitesse d'√©coulement, √©rosion |\n",
    "| aspect | Orientation (¬∞) | Ensoleillement, √©vaporation |\n",
    "\n",
    "**Fichiers cr√©√©s :**\n",
    "\n",
    "| Fichier | Description |\n",
    "|---------|-------------|\n",
    "| dem_features_training.csv | Features pour l'entra√Ænement |\n",
    "| dem_features_validation.csv | Features pour la validation |\n",
    "\n",
    "**Prochaine √©tape :**\n",
    "- Fusionner tous les CSV (Landsat, TerraClimate, WorldCover, SoilGrids, DEM, Water Type)\n",
    "- R√©entra√Æner le mod√®le avec toutes les nouvelles features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
