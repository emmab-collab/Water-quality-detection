{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro-md",
   "metadata": {},
   "source": [
    "# Modélisation V2 - Avec Toutes les Nouvelles Features\n",
    "\n",
    "## Objectif\n",
    "\n",
    "Comparer les performances du modèle **avant** et **après** l'ajout des nouvelles features.\n",
    "\n",
    "## Baseline (avant)\n",
    "\n",
    "- **R² max : ~0.41** avec Random Forest\n",
    "- Features : Landsat + TerraClimate (~35 features)\n",
    "\n",
    "## Nouvelles features ajoutées\n",
    "\n",
    "| Source | Features | Description |\n",
    "|--------|----------|-------------|\n",
    "| Landsat V2 | +10 | Stats (std) + buffer 200m |\n",
    "| TerraClimate V2 | +24 | Lags, cumuls, anomalies |\n",
    "| ESA WorldCover | +8 | % occupation du sol |\n",
    "| SoilGrids | +6 | Propriétés du sol |\n",
    "| DEM | +3 | Altitude, pente, orientation |\n",
    "| Water Type | +1 | Rivière / lac |\n",
    "\n",
    "## Modèles à tester\n",
    "\n",
    "1. Random Forest (baseline)\n",
    "2. XGBoost\n",
    "3. LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation des dépendances si nécessaire\n",
    "!pip install xgboost lightgbm --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Modèles\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 1 : Charger les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données fusionnées\n",
    "train_df = pd.read_csv(\"../data/processed/merged_training.csv\")\n",
    "test_df = pd.read_csv(\"../data/processed/merged_validation.csv\")\n",
    "\n",
    "print(f\"Training : {train_df.shape}\")\n",
    "print(f\"Validation : {test_df.shape}\")\n",
    "\n",
    "print(f\"\\nColonnes : {len(train_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "targets-cell",
   "metadata": {},
   "outputs": [],
   "source": "# Variables cibles (noms réels dans le dataset)\nTARGET_COLS = ['Total Alkalinity', 'Electrical Conductance', 'Dissolved Reactive Phosphorus']\n\n# Noms courts pour l'affichage\nTARGET_NAMES = ['Alkalinity', 'Conductivity', 'Phosphorus']\n\n# Colonnes à exclure des features\nEXCLUDE_COLS = ['Latitude', 'Longitude', 'Sample Date'] + TARGET_COLS\n\n# Features\nfeature_cols = [c for c in train_df.columns if c not in EXCLUDE_COLS]\nprint(f\"Nombre de features : {len(feature_cols)}\")\nprint(f\"Variables cibles : {TARGET_COLS}\")"
  },
  {
   "cell_type": "markdown",
   "id": "prep-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 2 : Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prep-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PRÉPARATION DES FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "def prepare_features(df, feature_cols):\n",
    "    \"\"\"\n",
    "    Prépare les features pour la modélisation.\n",
    "    - Encode les variables catégorielles\n",
    "    - Gère les valeurs manquantes\n",
    "    \"\"\"\n",
    "    X = df[feature_cols].copy()\n",
    "    \n",
    "    # Encoder water_type si présent\n",
    "    if 'water_type' in X.columns:\n",
    "        le = LabelEncoder()\n",
    "        X['water_type'] = le.fit_transform(X['water_type'].fillna('unknown'))\n",
    "    \n",
    "    # Convertir toutes les colonnes en numérique\n",
    "    for col in X.columns:\n",
    "        if X[col].dtype == 'object':\n",
    "            try:\n",
    "                X[col] = pd.to_numeric(X[col], errors='coerce')\n",
    "            except:\n",
    "                X[col] = LabelEncoder().fit_transform(X[col].fillna('unknown'))\n",
    "    \n",
    "    # Remplir les valeurs manquantes par la médiane\n",
    "    X = X.fillna(X.median())\n",
    "    \n",
    "    return X\n",
    "\n",
    "# Préparer les features\n",
    "X_train = prepare_features(train_df, feature_cols)\n",
    "X_test = prepare_features(test_df, feature_cols)\n",
    "\n",
    "print(f\"X_train : {X_train.shape}\")\n",
    "print(f\"X_test : {X_test.shape}\")\n",
    "\n",
    "# Vérifier les valeurs manquantes\n",
    "print(f\"\\nValeurs manquantes (train) : {X_train.isnull().sum().sum()}\")\n",
    "print(f\"Valeurs manquantes (test) : {X_test.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SPLIT TRAIN/VALIDATION\n",
    "# =============================================================================\n",
    "\n",
    "# Variables cibles\n",
    "y_train = train_df[TARGET_COLS].copy()\n",
    "\n",
    "# Split pour évaluation\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train : {X_tr.shape}\")\n",
    "print(f\"Validation : {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 3 : Random Forest (Baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RANDOM FOREST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Random Forest\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "rf_scores = {}\n",
    "rf_models = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    print(f\"\\n{target}:\")\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    rf.fit(X_tr, y_tr[target])\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred = rf.predict(X_val)\n",
    "    \n",
    "    # Scores\n",
    "    r2 = r2_score(y_val[target], y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val[target], y_pred))\n",
    "    \n",
    "    rf_scores[target] = {'R2': r2, 'RMSE': rmse}\n",
    "    rf_models[target] = rf\n",
    "    \n",
    "    print(f\"  R² = {r2:.4f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "\n",
    "# Score moyen\n",
    "mean_r2_rf = np.mean([s['R2'] for s in rf_scores.values()])\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"R² MOYEN (Random Forest) : {mean_r2_rf:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xgb-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 4 : XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xgb-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# XGBOOST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"XGBoost\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "xgb_scores = {}\n",
    "xgb_models = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    print(f\"\\n{target}:\")\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    xgb_model = xgb.XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    )\n",
    "    xgb_model.fit(X_tr, y_tr[target])\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred = xgb_model.predict(X_val)\n",
    "    \n",
    "    # Scores\n",
    "    r2 = r2_score(y_val[target], y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val[target], y_pred))\n",
    "    \n",
    "    xgb_scores[target] = {'R2': r2, 'RMSE': rmse}\n",
    "    xgb_models[target] = xgb_model\n",
    "    \n",
    "    print(f\"  R² = {r2:.4f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "\n",
    "# Score moyen\n",
    "mean_r2_xgb = np.mean([s['R2'] for s in xgb_scores.values()])\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"R² MOYEN (XGBoost) : {mean_r2_xgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lgb-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 5 : LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lgb-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LIGHTGBM\n",
    "# =============================================================================\n",
    "\n",
    "print(\"LightGBM\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "lgb_scores = {}\n",
    "lgb_models = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    print(f\"\\n{target}:\")\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    lgb_model = lgb.LGBMRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=8,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    )\n",
    "    lgb_model.fit(X_tr, y_tr[target])\n",
    "    \n",
    "    # Prédictions\n",
    "    y_pred = lgb_model.predict(X_val)\n",
    "    \n",
    "    # Scores\n",
    "    r2 = r2_score(y_val[target], y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val[target], y_pred))\n",
    "    \n",
    "    lgb_scores[target] = {'R2': r2, 'RMSE': rmse}\n",
    "    lgb_models[target] = lgb_model\n",
    "    \n",
    "    print(f\"  R² = {r2:.4f}\")\n",
    "    print(f\"  RMSE = {rmse:.2f}\")\n",
    "\n",
    "# Score moyen\n",
    "mean_r2_lgb = np.mean([s['R2'] for s in lgb_scores.values()])\n",
    "print(f\"\\n{'=' * 50}\")\n",
    "print(f\"R² MOYEN (LightGBM) : {mean_r2_lgb:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compare-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 6 : Comparaison des modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-cell",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# COMPARAISON\n# =============================================================================\n\nprint(\"COMPARAISON DES MODÈLES\")\nprint(\"=\" * 60)\n\n# Créer un tableau récapitulatif\ncomparison = pd.DataFrame({\n    'Random Forest': [rf_scores[t]['R2'] for t in TARGET_COLS],\n    'XGBoost': [xgb_scores[t]['R2'] for t in TARGET_COLS],\n    'LightGBM': [lgb_scores[t]['R2'] for t in TARGET_COLS],\n}, index=TARGET_NAMES)  # Utiliser les noms courts pour l'affichage\n\n# Ajouter la moyenne\ncomparison.loc['MOYENNE'] = comparison.mean()\n\nprint(\"\\nR² par variable cible :\")\ndisplay(comparison.round(4))\n\n# Meilleur modèle\nbest_model = comparison.loc['MOYENNE'].idxmax()\nbest_score = comparison.loc['MOYENNE'].max()\n\nprint(f\"\\n{'=' * 60}\")\nprint(f\"MEILLEUR MODÈLE : {best_model} (R² moyen = {best_score:.4f})\")\nprint(f\"\\nComparaison avec baseline :\")\nprint(f\"  Avant (baseline) : R² = 0.41\")\nprint(f\"  Après (nouvelles features) : R² = {best_score:.4f}\")\nprint(f\"  Amélioration : +{(best_score - 0.41):.4f} ({((best_score - 0.41) / 0.41 * 100):.1f}%)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-compare",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# VISUALISATION\n# =============================================================================\n\nfig, ax = plt.subplots(figsize=(10, 6))\n\nx = np.arange(len(TARGET_COLS))\nwidth = 0.25\n\nbars1 = ax.bar(x - width, [rf_scores[t]['R2'] for t in TARGET_COLS], width, label='Random Forest')\nbars2 = ax.bar(x, [xgb_scores[t]['R2'] for t in TARGET_COLS], width, label='XGBoost')\nbars3 = ax.bar(x + width, [lgb_scores[t]['R2'] for t in TARGET_COLS], width, label='LightGBM')\n\n# Ligne baseline\nax.axhline(y=0.41, color='red', linestyle='--', label='Baseline (0.41)')\n\nax.set_xlabel('Variable cible')\nax.set_ylabel('R²')\nax.set_title('Comparaison des modèles par variable cible')\nax.set_xticks(x)\nax.set_xticklabels(TARGET_NAMES)  # Noms courts\nax.legend()\nax.set_ylim(0, 1)\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "importance-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 7 : Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "importance-cell",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# FEATURE IMPORTANCE (meilleur modèle)\n# =============================================================================\n\n# Utiliser le meilleur modèle\nif best_model == 'Random Forest':\n    models = rf_models\nelif best_model == 'XGBoost':\n    models = xgb_models\nelse:\n    models = lgb_models\n\nfig, axes = plt.subplots(1, 3, figsize=(15, 6))\n\nfor idx, (target, target_name) in enumerate(zip(TARGET_COLS, TARGET_NAMES)):\n    model = models[target]\n    \n    # Récupérer l'importance\n    importance = model.feature_importances_\n    feature_importance = pd.DataFrame({\n        'feature': feature_cols,\n        'importance': importance\n    }).sort_values('importance', ascending=False)\n    \n    # Top 15\n    top_features = feature_importance.head(15)\n    \n    ax = axes[idx]\n    ax.barh(range(len(top_features)), top_features['importance'].values)\n    ax.set_yticks(range(len(top_features)))\n    ax.set_yticklabels(top_features['feature'].values)\n    ax.invert_yaxis()\n    ax.set_title(f'{target_name}\\n(Top 15 features)')\n    ax.set_xlabel('Importance')\n\nplt.suptitle(f'Feature Importance ({best_model})', fontsize=14)\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "submit-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Étape 8 : Générer les prédictions pour la soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retrain-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RÉENTRAÎNER SUR TOUTES LES DONNÉES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"Réentraînement avec {best_model} sur toutes les données...\")\n",
    "\n",
    "final_models = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    print(f\"  {target}...\", end=\" \")\n",
    "    \n",
    "    if best_model == 'Random Forest':\n",
    "        model = RandomForestRegressor(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "    elif best_model == 'XGBoost':\n",
    "        model = xgb.XGBRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=0\n",
    "        )\n",
    "    else:  # LightGBM\n",
    "        model = lgb.LGBMRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=8,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            verbosity=-1\n",
    "        )\n",
    "    \n",
    "    model.fit(X_train, y_train[target])\n",
    "    final_models[target] = model\n",
    "    print(\"OK\")\n",
    "\n",
    "print(\"\\nModèles entraînés !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "predict-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PRÉDICTIONS SUR LE JEU DE TEST\n",
    "# =============================================================================\n",
    "\n",
    "print(\"Génération des prédictions...\")\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for target in TARGET_COLS:\n",
    "    pred = final_models[target].predict(X_test)\n",
    "    \n",
    "    # S'assurer que les prédictions sont positives\n",
    "    pred = np.maximum(pred, 0)\n",
    "    \n",
    "    predictions[target] = pred\n",
    "    print(f\"  {target}: min={pred.min():.2f}, max={pred.max():.2f}, mean={pred.mean():.2f}\")\n",
    "\n",
    "print(\"\\nPrédictions générées !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "submission-cell",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# CRÉER LE FICHIER DE SOUMISSION\n# =============================================================================\n\n# Charger le template\nsubmission = pd.read_csv(\"../data/raw/submission_template.csv\")\n\n# Mapping des noms de colonnes (template -> nos noms)\n# Vérifier les noms dans le template\nprint(\"Colonnes du template :\")\nprint(list(submission.columns))\n\n# Ajouter les prédictions avec les bons noms\nfor target in TARGET_COLS:\n    if target in submission.columns:\n        submission[target] = predictions[target]\n    else:\n        # Le template peut avoir des noms différents\n        print(f\"⚠️ Colonne '{target}' non trouvée dans le template\")\n\n# Vérifier\nprint(f\"\\nFichier de soumission :\")\nprint(f\"  Shape : {submission.shape}\")\n\ndisplay(submission.head())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAUVEGARDER\n",
    "# =============================================================================\n",
    "\n",
    "submission_path = \"../data/submission.csv\"\n",
    "submission.to_csv(submission_path, index=False)\n",
    "\n",
    "print(f\"✅ Fichier de soumission sauvegardé : {submission_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-md",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Résumé\n",
    "\n",
    "### Comparaison avant/après\n",
    "\n",
    "| Métrique | Avant | Après | Amélioration |\n",
    "|----------|-------|-------|-------------|\n",
    "| R² moyen | 0.41 | ? | ? |\n",
    "| Nb features | ~35 | ~75 | +40 |\n",
    "\n",
    "### Nouvelles sources de données utilisées\n",
    "\n",
    "- Landsat V2 (buffer + stats)\n",
    "- TerraClimate V2 (lags + cumuls)\n",
    "- ESA WorldCover (occupation du sol)\n",
    "- SoilGrids (propriétés du sol)\n",
    "- DEM (topographie)\n",
    "- Water Type (rivière/lac)\n",
    "\n",
    "### Fichier créé\n",
    "\n",
    "- `submission.csv` : Prédictions pour la soumission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}