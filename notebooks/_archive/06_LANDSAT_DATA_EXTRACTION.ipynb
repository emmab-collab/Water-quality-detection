{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Landsat - Compl√©tion du Dataset Existant\n",
    "\n",
    "## Strat√©gie d'extraction\n",
    "\n",
    "Nous avons d√©j√† un fichier `landsat_features_training.csv` avec :\n",
    "- **8234 lignes** avec donn√©es : nir, green, swir16, swir22, NDMI, MNDWI\n",
    "- **1085 lignes** sans donn√©es (NaN)\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  DONN√âES EXISTANTES (landsat_features_training.csv)         ‚îÇ\n",
    "‚îÇ  ‚Ä¢ 8234 lignes avec: nir, green, swir16, swir22, NDMI, MNDWI‚îÇ\n",
    "‚îÇ  ‚Ä¢ 1085 lignes sans donn√©es (NaN)                           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                            ‚îÇ\n",
    "        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "        ‚ñº                                       ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  √âTAPE 1 (~2h)        ‚îÇ           ‚îÇ  √âTAPE 2 (~20min)     ‚îÇ\n",
    "‚îÇ  8234 lignes          ‚îÇ           ‚îÇ  1085 lignes          ‚îÇ\n",
    "‚îÇ                       ‚îÇ           ‚îÇ                       ‚îÇ\n",
    "‚îÇ  Extraire: blue, red  ‚îÇ           ‚îÇ  Extraire: TOUTES     ‚îÇ\n",
    "‚îÇ  Calculer: NDVI, NDWI ‚îÇ           ‚îÇ  bandes (seuil 30%)   ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "        ‚îÇ                                       ‚îÇ\n",
    "        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "                            ‚ñº\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ  √âTAPE 3: FUSION                                            ‚îÇ\n",
    "‚îÇ  Fichier final: 10 variables pour ~9300 lignes              ‚îÇ\n",
    "‚îÇ  blue, green, red, nir, swir16, swir22, NDVI, NDWI, NDMI,   ‚îÇ\n",
    "‚îÇ  MNDWI                                                      ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "## Source des donn√©es\n",
    "\n",
    "[Landsat Collection 2 Level 2 sur Planetary Computer](https://planetarycomputer.microsoft.com/dataset/landsat-c2-l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-install",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Installation des d√©pendances\n",
    "\n",
    "‚ö†Ô∏è **Premi√®re ex√©cution uniquement** : Red√©marrer le kernel apr√®s cette cellule."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install-deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q odc-stac planetary-computer pystac-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystac_client\n",
    "import planetary_computer as pc\n",
    "from odc.stac import stac_load\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "print(\"Imports OK!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURATION\n",
    "# =============================================================================\n",
    "\n",
    "# Toutes les bandes spectrales\n",
    "ALL_BANDS = [\"blue\", \"green\", \"red\", \"nir08\", \"swir16\", \"swir22\"]\n",
    "\n",
    "# Bandes √† extraire pour l'√©tape 1 (nouvelles variables)\n",
    "BANDS_STEP1 = [\"blue\", \"red\"]\n",
    "\n",
    "# P√©riode de recherche\n",
    "DATE_RANGE = \"2011-01-01/2015-12-31\"\n",
    "\n",
    "# Seuils de couverture nuageuse\n",
    "MAX_CLOUD_COVER_STRICT = 10   # Pour l'√©tape 1\n",
    "MAX_CLOUD_COVER_RELAXED = 30  # Pour l'√©tape 2 (donn√©es manquantes)\n",
    "\n",
    "# Nombre de workers parall√®les\n",
    "N_WORKERS = 8\n",
    "\n",
    "# Chemins des fichiers\n",
    "EXISTING_FILE = \"../data/processed/landsat_features_training.csv\"\n",
    "WATER_QUALITY_FILE = \"../data/raw/water_quality_training_dataset.csv\"\n",
    "OUTPUT_DIR = \"../data/processed\"\n",
    "\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - √âtape 1: Extraire {BANDS_STEP1} (seuil nuages: {MAX_CLOUD_COVER_STRICT}%)\")\n",
    "print(f\"  - √âtape 2: Extraire {ALL_BANDS} (seuil nuages: {MAX_CLOUD_COVER_RELAXED}%)\")\n",
    "print(f\"  - Workers: {N_WORKERS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explain-bands",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Comprendre les donn√©es Landsat\n",
    "\n",
    "### Les bandes spectrales\n",
    "\n",
    "```\n",
    "Spectre √©lectromagn√©tique :\n",
    "\n",
    "    Visible                    Infrarouge\n",
    "    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "    ‚îÇ  Blue  Green  Red  ‚îÇ  NIR     SWIR16     SWIR22      ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "     0.4    0.5   0.6    0.8      1.6        2.2    (Œºm)\n",
    "```\n",
    "\n",
    "| Bande | Utilit√© pour la qualit√© de l'eau |\n",
    "|-------|----------------------------------|\n",
    "| **blue** | P√©n√®tre l'eau profonde, a√©rosols |\n",
    "| **green** | Turbidit√©, algues |\n",
    "| **red** | Chlorophylle, v√©g√©tation |\n",
    "| **nir08** | Distingue eau/v√©g√©tation |\n",
    "| **swir16** | Humidit√© du sol |\n",
    "| **swir22** | Min√©raux, types de sol |\n",
    "\n",
    "### Indices spectraux\n",
    "\n",
    "| Indice | Formule | Interpr√©tation |\n",
    "|--------|---------|----------------|\n",
    "| **NDVI** | (NIR-Red)/(NIR+Red) | V√©g√©tation : >0.3 = dense |\n",
    "| **NDWI** | (Green-NIR)/(Green+NIR) | Eau : >0 = eau |\n",
    "| **NDMI** | (NIR-SWIR16)/(NIR+SWIR16) | Humidit√© : >0.4 = humide |\n",
    "| **MNDWI** | (Green-SWIR16)/(Green+SWIR16) | Surfaces d'eau libre |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "func-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fonctions d'extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "func-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# FONCTION D'EXTRACTION G√âN√âRIQUE (AVEC SAUVEGARDE INCR√âMENTALE)\n",
    "# =============================================================================\n",
    "\n",
    "def extract_landsat(df, bands, max_cloud_cover, n_workers=N_WORKERS, \n",
    "                    save_every=100, backup_path=\"../data/processed/extraction_backup.csv\"):\n",
    "    \"\"\"\n",
    "    Extrait les valeurs Landsat pour les points d'un DataFrame.\n",
    "    AVEC SAUVEGARDE INCR√âMENTALE pour √©viter de perdre les donn√©es.\n",
    "\n",
    "    Param√®tres :\n",
    "        df : DataFrame avec 'Latitude', 'Longitude', 'Sample Date'\n",
    "        bands : Liste des bandes √† extraire (ex: [\"blue\", \"red\"])\n",
    "        max_cloud_cover : Seuil de couverture nuageuse max (%)\n",
    "        n_workers : Nombre de threads parall√®les\n",
    "        save_every : Sauvegarder tous les N points (d√©faut: 100)\n",
    "        backup_path : Chemin du fichier de sauvegarde\n",
    "\n",
    "    Retourne :\n",
    "        DataFrame avec les valeurs des bandes Landsat\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy().reset_index(drop=True)\n",
    "    results = {band: np.full(len(df), np.nan) for band in bands}\n",
    "    completed_count = 0\n",
    "\n",
    "    print(f\"Extraction de {bands} pour {len(df)} points\")\n",
    "    print(f\"  Seuil nuages: {max_cloud_cover}% | Workers: {n_workers}\")\n",
    "    print(f\"  Sauvegarde automatique tous les {save_every} points ‚Üí {backup_path}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    def extract_point(args):\n",
    "        \"\"\"Extrait les donn√©es pour un point.\"\"\"\n",
    "        idx, lat, lon, sample_date = args\n",
    "\n",
    "        try:\n",
    "            # V√©rifier la date\n",
    "            if pd.isna(sample_date):\n",
    "                return idx, {band: np.nan for band in bands}\n",
    "\n",
    "            if isinstance(sample_date, str):\n",
    "                sample_date = pd.to_datetime(sample_date, dayfirst=True, errors='coerce')\n",
    "            if pd.isna(sample_date):\n",
    "                return idx, {band: np.nan for band in bands}\n",
    "\n",
    "            # Bounding box (~100m autour du point)\n",
    "            buffer = 0.001  # ~100m en degr√©s\n",
    "            bbox = [lon - buffer, lat - buffer, lon + buffer, lat + buffer]\n",
    "\n",
    "            # Connexion au catalogue\n",
    "            catalog = pystac_client.Client.open(\n",
    "                \"https://planetarycomputer.microsoft.com/api/stac/v1\",\n",
    "                modifier=pc.sign_inplace,\n",
    "            )\n",
    "\n",
    "            # Recherche des sc√®nes Landsat\n",
    "            search = catalog.search(\n",
    "                collections=[\"landsat-c2-l2\"],\n",
    "                bbox=bbox,\n",
    "                datetime=DATE_RANGE,\n",
    "                query={\"eo:cloud_cover\": {\"lt\": max_cloud_cover}},\n",
    "            )\n",
    "            items = list(search.item_collection())\n",
    "\n",
    "            if not items:\n",
    "                return idx, {band: np.nan for band in bands}\n",
    "\n",
    "            # S√©lectionner la sc√®ne la plus proche de la date\n",
    "            sample_date_utc = sample_date.tz_localize(\"UTC\") if sample_date.tzinfo is None else sample_date\n",
    "            best_item = min(items, key=lambda x: abs(\n",
    "                pd.to_datetime(x.properties[\"datetime\"]).tz_convert(\"UTC\") - sample_date_utc\n",
    "            ))\n",
    "\n",
    "            # Charger les donn√©es\n",
    "            signed_item = pc.sign(best_item)\n",
    "            data = stac_load([signed_item], bands=bands, bbox=bbox).isel(time=0)\n",
    "\n",
    "            # Extraire la m√©diane pour chaque bande\n",
    "            result = {}\n",
    "            for band in bands:\n",
    "                val = float(data[band].astype(\"float\").median(skipna=True).values)\n",
    "                result[band] = val if val != 0 else np.nan\n",
    "\n",
    "            return idx, result\n",
    "\n",
    "        except Exception:\n",
    "            return idx, {band: np.nan for band in bands}\n",
    "\n",
    "    # Pr√©parer les arguments\n",
    "    args_list = [\n",
    "        (idx, df.loc[idx, 'Latitude'], df.loc[idx, 'Longitude'], df.loc[idx, 'Sample Date'])\n",
    "        for idx in df.index\n",
    "    ]\n",
    "\n",
    "    # Extraction parall√®le avec sauvegarde incr√©mentale\n",
    "    with ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        futures = {executor.submit(extract_point, args): args[0] for args in args_list}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Extraction\"):\n",
    "            try:\n",
    "                idx, point_results = future.result(timeout=60)  # Timeout de 60s par point\n",
    "                for band in bands:\n",
    "                    if band in point_results:\n",
    "                        results[band][idx] = point_results[band]\n",
    "                \n",
    "                completed_count += 1\n",
    "                \n",
    "                # Sauvegarde incr√©mentale\n",
    "                if completed_count % save_every == 0:\n",
    "                    backup_df = pd.DataFrame(results)\n",
    "                    backup_df.to_csv(backup_path, index=False)\n",
    "                    print(f\"\\nüíæ Sauvegarde: {completed_count}/{len(df)} points ‚Üí {backup_path}\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                pass\n",
    "\n",
    "    # Sauvegarde finale\n",
    "    final_df = pd.DataFrame(results)\n",
    "    final_df.to_csv(backup_path, index=False)\n",
    "    print(f\"\\n‚úÖ Extraction termin√©e! Sauvegarde finale: {backup_path}\")\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "print(\"Fonction extract_landsat() d√©finie (avec sauvegarde incr√©mentale)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "func-indices",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CALCUL DES INDICES SPECTRAUX\n",
    "# =============================================================================\n",
    "\n",
    "def compute_spectral_indices(df):\n",
    "    \"\"\"\n",
    "    Calcule les indices spectraux √† partir des bandes Landsat.\n",
    "    N√©cessite : nir (ou nir08), green, red, swir16\n",
    "    \"\"\"\n",
    "\n",
    "    df = df.copy()\n",
    "    eps = 1e-10  # √âviter division par z√©ro\n",
    "\n",
    "    # G√©rer le nom de la colonne NIR (nir ou nir08)\n",
    "    nir_col = 'nir' if 'nir' in df.columns else 'nir08'\n",
    "\n",
    "    # NDVI = (NIR - Red) / (NIR + Red)\n",
    "    if 'red' in df.columns:\n",
    "        df['NDVI'] = (df[nir_col] - df['red']) / (df[nir_col] + df['red'] + eps)\n",
    "\n",
    "    # NDWI = (Green - NIR) / (Green + NIR)\n",
    "    if 'green' in df.columns:\n",
    "        df['NDWI'] = (df['green'] - df[nir_col]) / (df['green'] + df[nir_col] + eps)\n",
    "\n",
    "    # NDMI = (NIR - SWIR16) / (NIR + SWIR16)\n",
    "    if 'swir16' in df.columns:\n",
    "        df['NDMI'] = (df[nir_col] - df['swir16']) / (df[nir_col] + df['swir16'] + eps)\n",
    "\n",
    "    # MNDWI = (Green - SWIR16) / (Green + SWIR16)\n",
    "    if 'green' in df.columns and 'swir16' in df.columns:\n",
    "        df['MNDWI'] = (df['green'] - df['swir16']) / (df['green'] + df['swir16'] + eps)\n",
    "\n",
    "    return df\n",
    "\n",
    "print(\"Fonction compute_spectral_indices() d√©finie!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Chargement des donn√©es existantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CHARGER LES DONN√âES EXISTANTES\n",
    "# =============================================================================\n",
    "\n",
    "# Charger le fichier Landsat existant\n",
    "existing_landsat = pd.read_csv(EXISTING_FILE)\n",
    "\n",
    "# Charger les donn√©es de qualit√© d'eau (pour avoir les coordonn√©es et dates)\n",
    "water_quality = pd.read_csv(WATER_QUALITY_FILE)\n",
    "\n",
    "print(f\"Fichier existant: {len(existing_landsat)} lignes\")\n",
    "print(f\"Colonnes existantes: {list(existing_landsat.columns)}\")\n",
    "\n",
    "# Identifier les lignes avec donn√©es et sans donn√©es\n",
    "# On v√©rifie si 'nir' (ou 'green') est NaN pour d√©terminer si on a des donn√©es\n",
    "has_data_mask = existing_landsat['nir'].notna() if 'nir' in existing_landsat.columns else existing_landsat['green'].notna()\n",
    "\n",
    "n_with_data = has_data_mask.sum()\n",
    "n_without_data = (~has_data_mask).sum()\n",
    "\n",
    "print(f\"\\nR√©partition:\")\n",
    "print(f\"  - Lignes avec donn√©es: {n_with_data}\")\n",
    "print(f\"  - Lignes sans donn√©es (NaN): {n_without_data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âTAPE 1 : Extraire blue/red pour les lignes avec donn√©es\n",
    "\n",
    "On extrait seulement les **nouvelles bandes** (blue, red) pour les lignes qui ont d√©j√† des donn√©es.\n",
    "Ensuite on calcule NDVI et NDWI.\n",
    "\n",
    "‚è±Ô∏è **Temps estim√©** : ~2 heures pour ~8200 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# √âTAPE 1 : EXTRACTION blue/red POUR LES LIGNES AVEC DONN√âES\n",
    "# =============================================================================\n",
    "\n",
    "# S√©lectionner les lignes qui ont d√©j√† des donn√©es\n",
    "df_with_data = water_quality[has_data_mask].copy()\n",
    "print(f\"√âtape 1: {len(df_with_data)} lignes √† traiter\")\n",
    "\n",
    "# Extraire seulement blue et red (AVEC SAUVEGARDE INCR√âMENTALE)\n",
    "new_bands = extract_landsat(\n",
    "    df_with_data,\n",
    "    bands=BANDS_STEP1,\n",
    "    max_cloud_cover=MAX_CLOUD_COVER_STRICT,\n",
    "    n_workers=N_WORKERS,\n",
    "    save_every=100,  # Sauvegarde tous les 100 points\n",
    "    backup_path=\"../data/processed/new_bands_backup.csv\"\n",
    ")\n",
    "\n",
    "print(f\"\\nExtraction termin√©e!\")\n",
    "print(f\"Valeurs manquantes:\")\n",
    "print(new_bands.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1-merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# √âTAPE 1 : FUSIONNER AVEC LES DONN√âES EXISTANTES\n",
    "# =============================================================================\n",
    "\n",
    "# Cr√©er une copie du dataframe existant pour les lignes avec donn√©es\n",
    "step1_result = existing_landsat[has_data_mask].copy().reset_index(drop=True)\n",
    "\n",
    "# Ajouter les nouvelles colonnes blue et red\n",
    "step1_result['blue'] = new_bands['blue'].values\n",
    "step1_result['red'] = new_bands['red'].values\n",
    "\n",
    "# Calculer NDVI et NDWI (on a maintenant red et nir)\n",
    "eps = 1e-10\n",
    "step1_result['NDVI'] = (step1_result['nir'] - step1_result['red']) / (step1_result['nir'] + step1_result['red'] + eps)\n",
    "step1_result['NDWI'] = (step1_result['green'] - step1_result['nir']) / (step1_result['green'] + step1_result['nir'] + eps)\n",
    "\n",
    "print(f\"√âtape 1 termin√©e: {len(step1_result)} lignes\")\n",
    "print(f\"Colonnes: {list(step1_result.columns)}\")\n",
    "display(step1_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âTAPE 2 : Extraire TOUTES les bandes pour les lignes NaN\n",
    "\n",
    "On extrait **toutes les bandes** pour les lignes qui n'ont pas de donn√©es.\n",
    "On utilise un seuil de nuages plus tol√©rant (30%) pour avoir plus de chances de trouver des images.\n",
    "\n",
    "‚è±Ô∏è **Temps estim√©** : ~20 minutes pour ~1000 points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2-extract",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# √âTAPE 2 : EXTRACTION COMPL√àTE POUR LES LIGNES NaN\n",
    "# =============================================================================\n",
    "\n",
    "# S√©lectionner les lignes sans donn√©es\n",
    "df_without_data = water_quality[~has_data_mask].copy()\n",
    "print(f\"√âtape 2: {len(df_without_data)} lignes √† traiter\")\n",
    "\n",
    "# Extraire toutes les bandes avec seuil relax√© (AVEC SAUVEGARDE INCR√âMENTALE)\n",
    "all_bands_result = extract_landsat(\n",
    "    df_without_data,\n",
    "    bands=ALL_BANDS,\n",
    "    max_cloud_cover=MAX_CLOUD_COVER_RELAXED,\n",
    "    n_workers=N_WORKERS,\n",
    "    save_every=100,\n",
    "    backup_path=\"../data/processed/all_bands_backup.csv\"\n",
    ")\n",
    "\n",
    "# Renommer nir08 -> nir\n",
    "all_bands_result = all_bands_result.rename(columns={'nir08': 'nir'})\n",
    "\n",
    "# Calculer les indices spectraux\n",
    "all_bands_result = compute_spectral_indices(all_bands_result)\n",
    "\n",
    "print(f\"\\nExtraction termin√©e!\")\n",
    "print(f\"Valeurs manquantes:\")\n",
    "print(all_bands_result.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2-prepare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# √âTAPE 2 : PR√âPARER LE DATAFRAME\n",
    "# =============================================================================\n",
    "\n",
    "# Cr√©er le dataframe pour l'√©tape 2 avec les m√™mes colonnes que l'√©tape 1\n",
    "step2_result = pd.DataFrame({\n",
    "    'Latitude': df_without_data['Latitude'].values,\n",
    "    'Longitude': df_without_data['Longitude'].values,\n",
    "    'Sample Date': df_without_data['Sample Date'].values,\n",
    "})\n",
    "\n",
    "# Ajouter les colonnes Landsat dans le bon ordre\n",
    "landsat_columns = ['nir', 'green', 'swir16', 'swir22', 'NDMI', 'MNDWI', 'blue', 'red', 'NDVI', 'NDWI']\n",
    "for col in landsat_columns:\n",
    "    if col in all_bands_result.columns:\n",
    "        step2_result[col] = all_bands_result[col].values\n",
    "    else:\n",
    "        step2_result[col] = np.nan\n",
    "\n",
    "print(f\"√âtape 2 termin√©e: {len(step2_result)} lignes\")\n",
    "display(step2_result.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-title",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## √âTAPE 3 : Fusion finale\n",
    "\n",
    "On fusionne les r√©sultats des √©tapes 1 et 2 pour cr√©er le fichier final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3-merge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# √âTAPE 3 : FUSION FINALE\n",
    "# =============================================================================\n",
    "\n",
    "# S'assurer que step1_result a les coordonn√©es\n",
    "if 'Latitude' not in step1_result.columns:\n",
    "    step1_result.insert(0, 'Latitude', df_with_data['Latitude'].values)\n",
    "    step1_result.insert(1, 'Longitude', df_with_data['Longitude'].values)\n",
    "    step1_result.insert(2, 'Sample Date', df_with_data['Sample Date'].values)\n",
    "\n",
    "# D√©finir l'ordre des colonnes\n",
    "final_columns = ['Latitude', 'Longitude', 'Sample Date',\n",
    "                 'blue', 'green', 'red', 'nir', 'swir16', 'swir22',\n",
    "                 'NDVI', 'NDWI', 'NDMI', 'MNDWI']\n",
    "\n",
    "# R√©ordonner les colonnes de step1_result\n",
    "step1_final = step1_result.reindex(columns=final_columns)\n",
    "\n",
    "# R√©ordonner les colonnes de step2_result\n",
    "step2_final = step2_result.reindex(columns=final_columns)\n",
    "\n",
    "# Concat√©ner les deux DataFrames\n",
    "final_df = pd.concat([step1_final, step2_final], ignore_index=True)\n",
    "\n",
    "print(f\"Dataset final: {len(final_df)} lignes\")\n",
    "print(f\"Colonnes: {list(final_df.columns)}\")\n",
    "print(f\"\\nValeurs manquantes:\")\n",
    "print(final_df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3-save",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SAUVEGARDE\n",
    "# =============================================================================\n",
    "\n",
    "# Sauvegarder le fichier final\n",
    "output_path = os.path.join(OUTPUT_DIR, 'landsat_features_training_complete.csv')\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Fichier sauvegard√© : {output_path}\")\n",
    "print(f\"  - {len(final_df)} lignes\")\n",
    "print(f\"  - {len(final_df.columns)} colonnes\")\n",
    "\n",
    "# Statistiques finales\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"R√âSUM√â FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total lignes: {len(final_df)}\")\n",
    "print(f\"\\nTaux de compl√©tion par variable:\")\n",
    "for col in ['blue', 'green', 'red', 'nir', 'swir16', 'swir22', 'NDVI', 'NDWI', 'NDMI', 'MNDWI']:\n",
    "    if col in final_df.columns:\n",
    "        taux = (1 - final_df[col].isna().mean()) * 100\n",
    "        print(f\"  {col}: {taux:.1f}%\")\n",
    "\n",
    "display(final_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "validation-title",
   "metadata": {},
   "source": "---\n\n## Extraction pour les donn√©es de submission (test)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "validation-extract",
   "metadata": {},
   "outputs": [],
   "source": "# =============================================================================\n# EXTRACTION SUBMISSION (TEST)\n# =============================================================================\n\n# Charger les donn√©es de submission\nsubmission_df = pd.read_csv('../data/raw/submission_template.csv')\nprint(f\"Submission : {len(submission_df)} lignes\")\n\n# Extraire toutes les bandes (AVEC SAUVEGARDE INCR√âMENTALE)\nsubmission_features = extract_landsat(\n    submission_df,\n    bands=ALL_BANDS,\n    max_cloud_cover=MAX_CLOUD_COVER_RELAXED,\n    n_workers=N_WORKERS,\n    save_every=100,\n    backup_path=\"../data/processed/submission_bands_backup.csv\"\n)\n\n# Renommer nir08 -> nir\nsubmission_features = submission_features.rename(columns={'nir08': 'nir'})\n\n# Calculer les indices spectraux\nsubmission_features = compute_spectral_indices(submission_features)\n\n# Cr√©er le DataFrame final avec coordonn√©es\nlandsat_submission_df = pd.DataFrame({\n    'Latitude': submission_df['Latitude'].values,\n    'Longitude': submission_df['Longitude'].values,\n    'Sample Date': submission_df['Sample Date'].values,\n})\n\n# Ajouter les bandes et indices\nfor col in ['blue', 'green', 'red', 'nir', 'swir16', 'swir22', 'NDVI', 'NDWI', 'NDMI', 'MNDWI']:\n    if col in submission_features.columns:\n        landsat_submission_df[col] = submission_features[col].values\n\n# Sauvegarder\noutput_path = \"../data/processed/landsat_features_submission.csv\"\nlandsat_submission_df.to_csv(output_path, index=False)\n\nprint(f\"\\n‚úÖ Fichier sauvegard√© : {output_path}\")\nprint(f\"  - {len(landsat_submission_df)} lignes\")\nprint(f\"  - {len(landsat_submission_df.columns)} colonnes\")\nprint(f\"\\nValeurs manquantes:\")\nprint(submission_features.isna().sum())"
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## R√©sum√©\n",
    "\n",
    "### Strat√©gie appliqu√©e\n",
    "\n",
    "| √âtape | Lignes | Bandes extraites | Seuil nuages |\n",
    "|-------|--------|------------------|--------------|\n",
    "| **1** | ~8234 | blue, red | 10% |\n",
    "| **2** | ~1085 | TOUTES | 30% |\n",
    "| **3** | ~9319 | Fusion | - |\n",
    "\n",
    "### Variables finales (10 au total)\n",
    "\n",
    "| Type | Variables |\n",
    "|------|-----------|\n",
    "| **Bandes (6)** | blue, green, red, nir, swir16, swir22 |\n",
    "| **Indices (4)** | NDVI, NDWI, NDMI, MNDWI |\n",
    "\n",
    "### Fichier cr√©√©\n",
    "\n",
    "`landsat_features_training_complete.csv` : Dataset complet avec 10 variables Landsat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}